{"model":"gpt-4o-mini","max_tokens":4000,"messages":[{"content":[{"text":"Your task is to analyze the provided image and generate **custom instructions** for converting its visual information into a structured JSON format. Focus on identifying **all elements** in the image and, most importantly, the **relationships and insights** between those elements. Use any surrounding text on the page to provide additional context or clarity about the diagram's purpose, themes, or connections. It is critical that your instructions capture these relationships and that they are properly reflected in the JSON. Your response should be customized instructions that can be used to prompt an LLM to process the image content into a JSON format accurately and reliably.\\n\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\n\\n1. **Analyze the Image**: Identify **all visible components** of the image. These could include text, numbers, shapes, icons, lines, arrows, colors, groupings, etc. Be thorough in listing all the individual elements, focusing on **relevant relationships and insights** between them. This is the most important part. Relationships could include:\\n  - Elements linked by lines or arrows (e.g., showing flow, sequence, or connection).\\n  - Groupings by location on axes or timelines, proximity, color, or other visual cues (e.g., items that belong to the same category, family, or set).\\n  - Comparisons between elements (e.g., sizes, positions, directions).\\n  - Directionality or sequence indicated by arrows, lines, or ordering.\\n  - Any other **interactions** that tie elements together, such as overlapping shapes, aligned elements, or color-coded regions.\\n  - Higher-level patterns or themes visible in the diagram, especially if clarified by surrounding text.\\n\\n2. **Describe Relationships in JSON**: For each relationship identified in the image, explain how to capture it in JSON. This might include:\\n  - Indicating a **direction** or **flow** between two elements connected by an arrow (e.g., `\\\"direction\\\":\\\"Element A flows to Element B\\\"`) if it conveys process or sequence.\\n  - **Grouping** elements that share a color, alignment, or proximity (e.g., `\\\"group\\\":\\\"green elements\\\",\\\"aligned_with\\\":\\\"central box\\\"`) to represent categories or clusters.\\n  - Expressing **comparative relationships** (e.g., `\\\"Element A is larger than Element B\\\"` or `\\\"Element A is above Element B\\\"`).\\n  - Assigning values from an axis or legend.\\n  - Capturing any patterns or trends, such as changes across a timeline, using surrounding text for additional insights.\\n  - Translate all keys, values, and text into English.\\n  - Here is an example that you should customize to fit the image, if relationships must be described:\\n```\\n{\\\"element\\\":\\\"A\\\",\\\"relationship\\\":{\\\"connected_to\\\":\\\"B\\\",\\\"direction\\\":\\\"left to right\\\"}}\\n```\\n\\n3. **Create a Summary JSON Object**: After analyzing the elements and relationships, create a summary JSON object that captures the **overall structure, context, and purpose** of the image, including the relationships you identified and any themes drawn from surrounding text.\\n  - Use specific examples from the image to show how to construct the summary, but avoid placeholders or general terms.\\n  - If the figure has a title or a number or both, such as table 1 or figure 2, it is ABSOLUTELY CRITICAL that you create instructions to capture these titles and numbers within the summary JSON object. In addition to preserving the title, create a key and value for the figure or table numbers like `{\\\"figure title\\\":\\\"TITLE\\\",\\\"figure number\\\": 1}` in **English**\\n    - The figure title or number may not be included in the image but may be found in the surrounding text.\\n    - Do not include the figure title and number if they cannot be found.\\n    - Use the nomenclature in the image. If the figure is called \\\"table\\\" call it \\\"table_title\\\" and  \\\"table_number\\\". etc...\\n  - If the image is a chart or graph, include a summary of the **overall trend** or **purpose** represented by the chart or graph in the summary JSON object!!!\\n  - **Only add fields like \\\"components\\\",\\\"trends\\\", or \\\"relationships\\\" if they offer key insights** about the image.\\n  - Example:\\n```\\n{\\\"figure_title\\\":\\\"Diagram of System Flow\\\",\\\"figure_number\\\":4,\\\"description\\\":\\\"X\\\",\\\"components\\\":[\\\"Z\\\"],\\\"trends\\\":[\\\"Q\\\"],\\\"relationships\\\":[{\\\"source\\\":\\\"Process A\\\",\\\"target\\\":\\\"Process B\\\",\\\"type\\\":\\\"flow\\\"},{\\\"group\\\":\\\"blue items\\\",\\\"elements\\\":[\\\"Box 1\\\",\\\"Box 2\\\"]}]}\\n```\\n\\n4. **Detailed JSON for Elements and Relationships**: For each individual component, provide detailed instructions on how to represent it as a JSON object.\\n  - Focus on **preserving relationships** between elements. Make sure that any lines, arrows, groupings, or comparisons are reflected in the JSON as attributes.\\n  - Ensure each JSON object includes attributes describing its relationships to other elements, such as:\\n    - `\\\"connected_to\\\":\\\"Element B\\\"`\\n    - `\\\"group\\\":\\\"blue items\\\"`\\n    - `\\\"relative_position\\\":\\\"above Element C\\\"`\\n  - Translate all keys, values, and text into English.\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\"Yes/No\\\", \\\"Male/Female\\\", \\\"Option A/Option B/Option C\\\") in your instructions.\\n    - Describe how to handle selection boxes:\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\"selected\\\": \\\"No\\\").\\n      - For single checkboxes without labels, use \\\"true\\\" or \\\"false\\\" based on whether the box is marked.\\n      - For multi-selections, list all selected values in an array.\\n    - **Precision**: Use examples matching the table's visible content, avoiding assumptions.\\n  - If the figure is a graph, bar chart or some other type of chart, create instructions to capture EVERY SINGLE data point in the chart.\\n    - It is ABSOLUTELY VITAL you **create instructions to capture every datapoint in the chart** COMPLETELY.\\n  - Include the relative changes between the data points in JSON as key-values.\\n  - Example:\\n```\\n{\\\"element\\\":\\\"Process A\\\",\\\"connected_to\\\":\\\"Process B\\\",\\\"direction\\\":\\\"flows to\\\"}\\n```\\n\\n5. **Narrative Instructions**: Provide guidance on how to convert the JSON into a narrative description. The narrative should describe the **relationships** between elements, clearly explaining how they connect or interact.\\n  - For example, \\\"Process A is connected to Process B, with an arrow showing a flow from left to right.\\\"\\n  - Avoid using placeholders like \\\"X\\\" or \\\"Y\\\"; base the narrative on the actual elements and relationships in the image.\\n\\n6. **Final Organization**: Once the individual JSON objects are described, instruct that the JSONL should be grouped at the top without indentation or extra formatting. The narrative description should be grouped at the bottom, representing the JSON content in sentence form. Ensure the narrative corresponds directly to the JSON and provides a full description of the image.\\n\\n**Key points to remember**:\\n\\n- **Everything must be in English**: Ensure that all JSON keys, values, and narrative text are written in English, including translations of any labels in the image in other languages.\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\n- **Use surrounding text for context**: Refer to additional text to help identify themes, relationships, or trends, as well as the title or figure number if they are not within the image itself.\\n- **Only add fields like \\\"components\\\",\\\"trends\\\", and \\\"relationships\\\"** if they offer meaningful insights about the image. Translate all keys, values, and text into English.\\n- **Figure/graph/chart title and number**: Create instructions to capture BOTH the figure title and number, if they exist, in the image. If they are not in the image, they may be found in the surrounding text. The entire figure title must be captured in **English** like this `{\\\"figure title\\\":\\\"TITLE\\\",\\\"figure number\\\":1}`, except translate \\\"figure title\\\" and \\\"figure number\\\" into English, as well as in the narrative text.\\n- Translate all keys, values, and text into English.\\n\\nThe goal is to ensure that the structure, relationships, and content of the image are fully captured in both JSON and the narrative, with insights enhanced by the surrounding text.\\n\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\n\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.","type":"text"}],"role":"system"},{"content":[{"text":"Analyze the below text from a document to infer what type of document it is and what the main themes, topics, and purpose of the document are. Create a concise summary of about 5-6 sentences in length, focusing solely on the important themes and points of this document.","type":"text"}],"role":"user"},{"content":[{"text":"This document describes the advancements in machine learning models, particularly focusing on the comparison between proprietary commercial models and open-source alternatives. It highlights three main aspects: parameter scale, image resolution, and multilingual capabilities, illustrating the performance gaps between these two categories. The document introduces InternVL 1.5, which aims to bridge these gaps through continuous learning, enhanced resolution, and improved bilingual proficiency. The main participants involved in this discussion include developers and researchers in the field of machine learning and artificial intelligence. The document emphasizes the need for improved performance in non-English scene understanding and optical character recognition tasks.\\n\\nKeywords: machine learning, proprietary models, open-source models, InternVL 1.5, multilingual capabilities, image resolution, parameter scale, OCR, artificial intelligence, continuous learning.","type":"text"}],"role":"assistant"},{"content":[{"text":"Here is the text that is on the same page as the graphic. It may or may not be relevant to the graphic:\\n\\n更为 复杂 的 内容 解析\\nThis gap is mainly reflected in the following three as-\\n pects : ( 1 ) Parameter Scale : Recent proprietary commer-\\n cial MLLMS [ 7 , 37 , 83 , 88 ] typically scales not less than\\n 100 billion parameters , while open - source models com-\\n monly employ a 300 million parameter vision foundation\\n model ( VFM ) , which is integrated with either a 7 billion\\n or 13 billion LLMs . ( 2 ) Image Resolution : Proprietary\\n commercial models typically employ a dynamic resolution\\n approach , preserving the original aspect ratio to facilitate\\n detailed scene and document understanding . In contrast ,\\n open - source models generally train with fixed resolutions\\n [ 20 , 25 , 58 , 67 , 112 , 137 ] , such as 336x336 and 448 × 448 ,\\n leading to a considerable gap in capabilities relative to com-\\n mercial counterparts . ( 3 ) Multilingual Capability : Propri-\\n etary models often leverage extensive multilingual datasets\\n for training , enhancing their performance across diverse\\n languages . However , open - source models predominantly\\n utilize English data , relying on the zero - shot capabilities of\\n LLMs for other languages , e.g. LLaVA - NeXT [ 60 ] . This re-\\n sults in sub - optimal performance in non - English scene un-\\n derstanding and OCR tasks .\\n1.5\\n InternVL\\nAGI\\nDynamic High - Resolution\\n448 4K Resolution\\nStrong Foundation Models\\n InternViT - 6B - 448px - V1.5 +\\nInternLM2-20B\\nHigh - Quality Bilingual Dataset\\n Captioning , General QA , Science ,\\n Chart , Mathematics , Knowledge ,\\n OCR , Document , Grounding ,\\n Conversation , Chinese , English\\nCharacteristics of InternVL 1.5 . Intern VL 1.5 features\\n representation through continuous learning , flexible\\n capabilities , and robust bilingual proficiency in English\\n, positioning it as a competitive MLLM .\\n30 % 及 以下\\n50 % -70 % ( 70 % )\\n26.43 %\\n22.91 %\\n30 % -50 % ( 50 % )\\n70 % -90 % ( 90 % )\\n39.21 %\\n5.29 %\\nTo bridge the gap , we introduce InternVL 1.5 , integrat-\\n ing three major improvements to enhance its performance\\n and usability . ( 1 ) We implement a continuous learning ap-\\n proach to a large - scale VFM - Intern ViT - 6B [ 20 ] , refining\\nFigure 2.\\n strong visual\\n resolution\\nand Chinese\\n第十五 届 中国 数据库 技术 大会\\nDATABASE TECHNOLOGY CONFERENCE CHINA 2024\\n行业 OCR 的 识别 度 普遍 在 70 %\\nDTCC\\n朗丽玆 西山 花园 酒店 8 月 22-24 日\\nDB2\\nMPP\\nIT - 168 .\\nU ChinaUnix\\nOracie\\nSQL\\nITPUB","type":"text"},{"image_url":{"url":"https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/1.jpg"},"type":"image_url"}],"role":"user"},{"content":[{"text":"Here is an image of a diagram or graphic. Your task is to analyze the image and provide **custom** instructions on how to convert the visual information into JSON format. **Do not paraphrase this task**. Instead, analyze the **specific relationships** within the image and create instructions based on the elements and how they are connected. Your response should be customized instructions that can be used to prompt an LLM to process the image content into a JSON format accurately and reliably.\\n\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\n\\n1. **List all components**: First, list all visible components in the image, such as text, numbers, arrows, lines, icons, shapes, and color coding.\\n  - Use any surrounding text to help clarify the purpose of each component, and explain what each component represents, with emphasis on how elements relate to each other:\\n  - Focus especially on **relationships** between elements, like directional arrows (e.g., flow or process sequence), placement on axes, groupings by color or proximity, and size or order comparisons. Be sure to describe each element's purpose, integrating any context provided by the text.\\n\\n2. **Describe the relationship in details**: For each relationship, explain what is being conveyed and the purpose of the connection (e.g., causal flow, comparison, importance). This might include directional arrows (e.g., showing flow or sequence), visual groupings (e.g., by color or alignment), or comparative relationships (e.g., sizes, positions, or importance).\\n  - Avoid listing elements without context—explain each relationship in detail if it adds clarity, and refer to surrounding text if it provides insight.\\n  - Be specific in describing how the relationships should be represented in JSON, rather than focusing solely on individual elements.\\n  - For diagrams, clarify what each connection represents and the intent behind the structure.\\n  - For graphs, highlight patterns, trends, or notable changes (e.g., upward/downward trends, fluctuations). Summarize these trends in your instructions to be captured in JSON.\\n\\n3. **Create Summary JSON**: After identifying the components, provide instructions for creating a **summary JSON object** that captures the overall structure, meaning, and context of the image. This should include any **figure titles**, **numbers**, headers, and main topics or themes in the image. Use actual examples from the image, avoiding generic placeholders.\\n  - Add customized appropriate fields for the image based on your analysis. For example, for graphs, you could add a \\\"trends\\\" field. For a flow diagram, something like \\\"components\\\" attribute might make sense. **Only add these fields if they highlight key insights about the image**!\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the image, especially for identifying the figure title and number if they are not within the image itself.\\n  - If a title or figure number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative.\\n    - Do not include the figure title and number if they cannot be found.\\n    - Use the nomenclature in the image. If the figure is called \\\"table\\\" call it \\\"table_title\\\" and  \\\"table_number\\\". etc...\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information and insights* being conveyed in the image. Use real values from the image and not default values:\\n```\\n{\\\"figure title\\\":\\\"TITLE\\\",\\\"figure number\\\":1,\\\"description\\\":\\\"X\\\",\\\"components\\\":[\\\"Z\\\"],\\\"trends\\\":[\\\"Q\\\"],\\\"relationships\\\":[{\\\"source\\\":\\\"Process A\\\",\\\"target\\\":\\\"Process B\\\",\\\"type\\\":\\\"flow\\\"},{\\\"group\\\":\\\"blue items\\\",\\\"elements\\\":[\\\"Box 1\\\",\\\"Box 2\\\"]}]}\\n```\\n  - Translate all keys, values, and text into English.\\n\\n4. **Create Detailed JSON for Elements and Relationships:**: Explain how to convert each individual component into JSON that reflects its relationships with other elements, if there are relationships between elements (e.g., arrows showing direction, data points on a graph).\\n  - The JSON should capture connections, groupings, directionality, trends or changes observed, and other relationships between the elements, not just the elements themselves.\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\"Yes/No\\\", \\\"Male/Female\\\", \\\"Option A/Option B/Option C\\\") in your instructions.\\n    - Describe how to handle selection boxes:\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\"selected\\\": \\\"No\\\").\\n      - For single checkboxes without labels, use \\\"true\\\" or \\\"false\\\" based on whether the box is marked.\\n      - For multi-selections, list all selected values in an array.\\n    - **Precision**: Use examples matching the table's visible content, avoiding assumptions.\\n  - For charts or data visualizations, capture every individual data point, including relative changes, and summarize the overall trend in the summary JSON object, using additional text to help explain overall patterns if relevant.\\n  - Translate all keys, values, and text into English.\\n\\n5. **Narrate the JSON**: Provide instructions on how to convert the JSON into full sentences. The narrative should describe each JSON object in English, detailing the relationships and meaning of each part of the image. Avoid using placeholders like \\\"X\\\" or \\\"Y\\\"—base the narrative on the actual content of the image.\\n\\n6. **Final JSONL and Narrative Instructions**: Instruct that the JSON objects should be grouped at the top in a JSONL format (without indentation or extra formatting). Below that, provide the narrative sentences that describe the JSON content fully.\\n\\n**Important Notes**:\\n- It is critical that your response is customized to the **relationships** and **insights** conveyed in the image, and not a paraphrase of these instructions.\\n- Use the surrounding text to capture additional context, high-level insights, or to capture the figure title and number if they are not visible within the image.\\n- If a title or figure number exists, make sure you capture this information in the summary JSON object and reflect it in the narrative. The figure number and title may not be in the image but may be found in the surrounding text.\\n- Only include fields like \\\"components\\\",\\\"trends\\\", and \\\"relationships\\\" in the summary JSON if they convey **key insights**.\\n- Make sure all relationships are captured, whether through arrows, lines, proximity, color coding, or other visual cues.\\n- Avoid placeholders like \\\"X\\\" or \\\"Y\\\"; use actual elements from the image and describe their relationships in detail.\\n- Translate all keys, values, and text into English.\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\n\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.","type":"text"}],"role":"user"},{"content":[{"image_url":{"url":"https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/figure-1-0.jpg"},"type":"image_url"}],"role":"user"}],"response_format":{"type":"text"},"stop":["==="],"temperature":0.3,"top_p":0.7}