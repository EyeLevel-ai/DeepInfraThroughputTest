{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbec58d3",
   "metadata": {},
   "source": [
    "# Querying Model List\n",
    "Getting the list of models on Kvant\n",
    "\n",
    "https://documentation.kvant.cloud/products/maas/supported_models/#1-call-to-list-available-models:~:text=Different%20Sample%20Calls-,%23,-1.%20Call%20to\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f517a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"inference-apertus-8b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-apertus-70b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-bge-m3\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-deepseekr1-70b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-deepseekr1-670b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-llama33-70b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-llama4-maverick\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-llama4-scout-17b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-kimi-k2\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-qwq-32b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-qwq25-vl-72b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-granite-33-8b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-granite-emb-278m\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-granite-vision-2b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-gemma-12b-it\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-gpt-oss-120b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-mistral-v03-7b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"inference-qwen3-8b\",\n",
      "      \"object\": \"model\",\n",
      "      \"created\": 1677610602,\n",
      "      \"owned_by\": \"openai\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KVANT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"KVANT_API_KEY not found in .env\")\n",
    "\n",
    "url = \"https://maas.ai-2.kvant.cloud/v1/models\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "try:\n",
    "    data = response.json()  # parse JSON\n",
    "    print(json.dumps(data, indent=2))  # pretty print\n",
    "except ValueError:\n",
    "    # If not JSON, just print text\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6d6d9",
   "metadata": {},
   "source": [
    "# Calling Chat Complete\n",
    "Asking a question to Gemma 12B\n",
    "\n",
    "https://documentation.kvant.cloud/products/maas/supported_models/#2-sample-calls-to-chat-completion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d782d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"id\": \"chatcmpl-91429f38-1e7d-4527-ae13-f7e476708c51\",\n",
      "  \"created\": 1759758027,\n",
      "  \"model\": \"hosted_vllm/infer-gemma-3-12b-it\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! \\ud83d\\ude0a \\n\\nIt's nice to hear from you! How are you doing today? What can I do for you?\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"provider_specific_fields\": {\n",
      "        \"stop_reason\": 106\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 28,\n",
      "    \"prompt_tokens\": 11,\n",
      "    \"total_tokens\": 39,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"service_tier\": null,\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KVANT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"KVANT_API_KEY not found in .env\")\n",
    "\n",
    "url = \"https://maas.ai-2.kvant.cloud/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"inference-gemma-12b-it\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, timeout=300)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "try:\n",
    "    data = response.json()\n",
    "    print(json.dumps(data, indent=2))\n",
    "except ValueError:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c77d8781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"id\": \"chatcmpl-879dfbb3-c5b6-40ba-8941-ddc89c00bddf\",\n",
      "  \"created\": 1759758050,\n",
      "  \"model\": \"hosted_vllm/infer-gemma-3-12b-it\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Okay, making sourdough bread is a rewarding but involved process. It's a journey of understanding your starter and the dough. Here's a comprehensive guide, broken down into phases, with plenty of detail.  I'll also include troubleshooting tips at the end. **Please read the *Important Notes* at the very bottom \\u2013 they're crucial.**\\n\\n**I. The Foundation: Your Sourdough Starter**\\n\\n* **What is it?** A living culture of wild yeast and bacteria (primarily *Lactobacillus*) that ferments flour and water, creating the characteristic sourdough flavor and rise.\\n* **Making a Starter (if you don't have one):** This takes about 7-14 days.\\n    1. **Day 1:** Mix 50g (approximately 1/4 cup) of unbleached all-purpose flour (or a mix of whole wheat and all-purpose) with 50g (approximately 1/4 cup) of non-chlorinated water (filtered or spring water is best) in a clean jar. Stir well. Loosely cover (cheesecloth secured with a rubber band is good).  Let it sit at room temperature (ideally 70-75\\u00b0F / 21-24\\u00b0C).\\n    2. **Day 2-7 (or longer):** You might not see anything. That's okay.  Once a day, stir the mixture well.  Observe for bubbles or a slight increase in volume.  Discard (throw away) about half of the starter and then \\\"feed\\\" it by adding 50g flour and 50g water.  Stir well and cover loosely.\\n    3. **Day 8 onwards:** You should start seeing bubbles and a rise in volume, often doubling in size within a few hours after feeding.  It should smell tangy (like yogurt or slightly sour).  This is a sign it's becoming active.  Continue feeding daily.\\n    4. **When is it ready?**  A mature starter will reliably double in size within 4-8 hours of feeding and have lots of bubbles. It will have a pleasant, tangy aroma.  A simple \\\"float test\\\" can help: drop a teaspoon of starter into a glass of water. If it floats, it's likely ready to bake with.\\n\\n* **Maintaining a Starter:** Once established, you can keep it at room temperature and feed it daily, or store it in the refrigerator and feed it once a week.  When refrigerating, feed it before storing it, and take it out a day or two before baking to reactivate it with daily feedings.\\n\\n**II. The Bread Recipe (Basic)**\\n\\nThis recipe makes one loaf.\\n\\n* **Ingredients:**\\n    * 100g (approximately 1/2 cup) Active Sourdough Starter (fed and bubbly)\\n    * 350g (approximately 1 1/2 cups) Unbleached All-Purpose Flour (or bread flour for a chewier crumb)\\n    * 250g (approximately 1 cup) Non-Chlorinated Water (lukewarm, around 80\\u00b0F / 27\\u00b0C)\\n    * 8-10g (approximately 1-1.25 tsp) Fine Sea Salt\\n\\n**III. The Process (Step-by-Step)**\\n\\n1. **Autolyse (30-60 minutes):** In a large bowl, mix the flour and water until just combined.  Don't overmix.  Cover and let it rest. This hydrates the flour and starts gluten development.\\n2. **Mix in Starter & Salt:** Add the active starter and salt to the autolysed dough. Mix thoroughly. This can be done by hand (about 5-10 minutes) or with a stand mixer (on low speed for 3-5 minutes). The dough will be shaggy.\\n3. **Bulk Fermentation (4-6 hours):** This is where the magic happens. The dough ferments, develops flavor, and rises.\\n    * **Stretch and Folds:** During the first 2-3 hours of bulk fermentation, perform \\\"stretch and folds\\\" every 30-60 minutes.  Gently stretch a portion of the dough upwards and fold it over itself. Rotate the bowl and repeat until you've stretched and folded the entire dough. This strengthens the gluten and distributes the fermentation.\\n    * **Rest:** After the initial stretch and folds, let the dough rest undisturbed for the remainder of the bulk fermentation.\\n    * **Monitoring:** The dough should increase in volume by about 30-50% and show signs of fermentation (bubbles).\\n4. **Pre-Shape:** Gently turn the dough out onto a lightly floured surface. Pre-shape into a round or oval. Let it rest, covered, for 15-30 minutes.\\n5. **Final Shape:** Shape the dough into your desired loaf shape (round or oval).\\n6. **Proofing (12-18 hours in refrigerator):** Place the shaped dough in a well-floured banneton (proofing basket) or a bowl lined with a floured cloth. Cover tightly and refrigerate overnight (or for up to 24 hours).  Cold proofing slows down fermentation and develops more flavor.\\n7. **Baking:**\\n    * **Preheat:** Preheat your oven to 500\\u00b0F (260\\u00b0C) with a Dutch oven inside for at least 30 minutes.\\n    * **Score:** Carefully remove the hot Dutch oven. Gently invert the dough from the banneton into the Dutch oven. Score the top of the loaf with a sharp knife or lame (a traditional sourdough scoring tool). This controls how the bread expands during baking.\\n    * **Bake Covered:** Cover the Dutch oven with the lid and bake for 20 minutes.\\n    * **Bake Uncovered:** Remove the lid and reduce the oven temperature to 450\\u00b0F (232\\u00b0C). Bake for another 25-35 minutes, or until the crust is deeply golden brown.\\n8. **Cooling:**  Remove the bread from the Dutch oven and let it cool completely on a wire rack *before* slicing (at least 2-3 hours \\u2013 this is crucial for the crumb to set).\\n\\n**IV. Troubleshooting**\\n\\n* **Flat Bread:**\\n    * **Weak Starter:** Your starter wasn't active enough. Continue feeding and observe its behavior.\\n    * **Under-Proofing:** The dough didn't rise enough during bulk fermentation or proofing.\\n    * **Over-Proofing:** The dough fermented too much, and the gluten structure collapsed.\\n* **Dense Crumb:**\\n    * **Under-Proofing:** Not enough fermentation.\\n    * **Too Much Flour:** Weigh your flour carefully.\\n* **Sour Bread:**\\n    * **Long Fermentation:**  Longer bulk fermentation and cold proofing will increase acidity.\\n* **Burnt Crust:**\\n    * **Oven Too Hot:** Lower the oven temperature slightly.\\n* **Gummy Crumb:**\\n    * **Cutting Too Soon:**  Let the bread cool completely.\\n      * **Underbaking:** Make sure the bread is fully baked.\\n\\n**V. Important Notes:**\\n\\n* **Weigh Ingredients:** Baking is a science. Weighing ingredients (especially flour) is *essential* for consistent results. Cups can vary greatly in volume.\\n* **Water Temperature:** Lukewarm water (around 80\\u00b0F / 27\\u00b0C) helps activate the yeast.\\n* **Temperature Matters:**  Room temperature and oven temperature significantly impact fermentation and baking.\\n* **Patience:** Sourdough baking takes time and practice. Don\\u2019t get discouraged if your first loaf isn't perfect.\\n* **Experiment:** Adjust the recipe and process to suit your environment and preferences.\\n* **Banneton/Proofing Basket:** While not strictly necessary, a banneton helps the loaf maintain its shape during proofing. You can use a bowl lined with a floured cloth as an alternative.\\n* **Dutch Oven:** The Dutch oven creates a steamy environment that helps the bread rise and develop a crispy crust.\\n\\n\\n\\nThis is a lot of information! Start with the basics, be patient, and enjoy the process of learning to bake sourdough bread. Good luck!\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"provider_specific_fields\": {\n",
      "        \"stop_reason\": 106\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1778,\n",
      "    \"prompt_tokens\": 16,\n",
      "    \"total_tokens\": 1794,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"service_tier\": null,\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KVANT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"KVANT_API_KEY not found in .env\")\n",
    "\n",
    "url = \"https://maas.ai-2.kvant.cloud/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"inference-gemma-12b-it\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"How do I make sourdough bread?\"}\n",
    "    ],\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, timeout=300)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "try:\n",
    "    data = response.json()\n",
    "    print(json.dumps(data, indent=2))\n",
    "except ValueError:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99a18bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "{\n",
      "  \"id\": \"chatcmpl-ebe22e5e-2391-4a34-9f24-b35ff4961ef0\",\n",
      "  \"created\": 1759771131,\n",
      "  \"model\": \"hosted_vllm/infer-gemma-3-12b-it\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"1. **\\ud14c\\uc774\\ube14 \\uad6c\\uc870 \\ubd84\\uc11d**: \\ud14c\\uc774\\ube14\\uc758 \\ubaa8\\ub4e0 \\ubcf4\\uc774\\ub294 \\uad6c\\uc131 \\uc694\\uc18c\\ub97c \\uc2dd\\ubcc4\\ud558\\uace0 \\ub098\\uc5f4\\ud569\\ub2c8\\ub2e4. \\ud14c\\uc774\\ube14 \\uc81c\\ubaa9, \\ud14c\\uc774\\ube14 \\ubc88\\ud638, \\uc5f4 \\uba38\\ub9ac\\uae00, \\ud589 \\uba38\\ub9ac\\uae00, \\ub370\\uc774\\ud130 \\uc140 \\ubc0f \\uae30\\ud0c0 \\uc2dc\\uac01\\uc801 \\uc694\\uc18c\\ub97c \\ud3ec\\ud568\\ud569\\ub2c8\\ub2e4. \\uc8fc\\ubcc0 \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc0ac\\uc6a9\\ud558\\uc5ec \\ud14c\\uc774\\ube14\\uc758 \\uad6c\\uc870\\uc640 \\ubaa9\\uc801\\uc744 \\uba85\\ud655\\ud788 \\ud569\\ub2c8\\ub2e4. \\uc5f4 \\uba38\\ub9ac\\uae00\\uacfc \\ub370\\uc774\\ud130 \\uc140 \\uac04\\uc758 \\uad00\\uacc4\\uc5d0 \\uc911\\uc810\\uc744 \\ub461\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uc5b4 \\uac01 \\uc5f4 \\uba38\\ub9ac\\uae00\\uc774 \\ud574\\ub2f9 \\uc5f4\\uc758 \\uac12\\uacfc \\uc5b4\\ub5bb\\uac8c \\uad00\\ub828\\ub418\\uc5b4 \\uc788\\uc2b5\\ub2c8\\uae4c? \\ud589 \\uba38\\ub9ac\\uae00\\uc774 \\ud589\\uc758 \\ub370\\uc774\\ud130\\uc640 \\uc5b4\\ub5bb\\uac8c \\uc0c1\\uc751\\ud569\\ub2c8\\uae4c?\\n\\n2. **\\uc694\\uc57d JSON \\uc9c0\\uce68**: \\ud14c\\uc774\\ube14 \\uc81c\\ubaa9, \\ubc88\\ud638 \\ubc0f \\uc8fc \\uba38\\ub9ac\\uae00\\uacfc \\uac19\\uc740 \\uace0\\uc218\\uc900 \\uc815\\ubcf4\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\uc694\\uc57d JSON \\uac1c\\uccb4\\ub97c \\ub9cc\\ub4dc\\ub294 \\ubc29\\ubc95\\uc5d0 \\ub300\\ud55c \\uc9c0\\uce68\\uc744 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4. \\ud14c\\uc774\\ube14\\uc758 \\ubaa9\\uc801, \\uc8fc\\uc694 \\uc8fc\\uc81c \\ub610\\ub294 \\ud14c\\ub9c8\\ub97c \\uc124\\uba85\\ud569\\ub2c8\\ub2e4. \\uc774\\ubbf8\\uc9c0\\uc5d0\\uc11c \\uc9c1\\uc811 \\uac00\\uc838\\uc628 \\uc608\\ub97c \\uc0ac\\uc6a9\\ud558\\uace0 \\uc77c\\ubc18\\uc801\\uc778 \\uc790\\ub9ac \\ud45c\\uc2dc\\uc790\\ub97c \\ud53c\\ud569\\ub2c8\\ub2e4.\\n\\n   - \\uc774\\ubbf8\\uc9c0\\uc5d0\\uc11c \\uc5bb\\uc740 \\ud1b5\\ucc30\\ub825\\uc744 \\uac15\\uc870\\ud558\\ub294 \\uacbd\\uc6b0 \\\"trends\\\"\\uc640 \\uac19\\uc740 \\ucd94\\uac00 \\ud544\\ub4dc\\ub97c \\ucd94\\uac00\\ud569\\ub2c8\\ub2e4.\\n     ```json\\n  {\\\"table_title\\\":\\\"\\uc18c\\ube44\\uc790 \\ubb3c\\uac00 \\uc99d\\uac10\\uc728 \\ucd94\\uc774\\\",\\\"table_number\\\":2,\\\"description\\\":\\\"'23.10\\uc6d4 ~ '24.3\\uc6d4 \\uc8fc\\uc694\\uad6d \\uc18c\\ube44\\uc790 \\ubb3c\\uac00 \\uc99d\\uac10\\uc728 \\ucd94\\uc774\\\",\\\"trends\\\":\\\"\\ubbf8\\uad6d \\uc18c\\ube44\\uc790 \\ubb3c\\uac00 \\uc0c1\\uc2b9\\ub960\\\"}\\n  ```\\n   - \\ud14c\\uc774\\ube14\\uc5d0 \\uc81c\\ubaa9\\uc774\\ub098 \\ubc88\\ud638\\uac00 \\uc5c6\\ub294 \\uacbd\\uc6b0 JSON\\uc774 \\uc774\\ub97c \\ubc18\\uc601\\ud558\\ub3c4\\ub85d \\uc9c0\\uc2dc\\ud569\\ub2c8\\ub2e4.\\n   - \\ubaa8\\ub4e0 \\ud0a4, \\uac12 \\ubc0f \\ud14d\\uc2a4\\ud2b8\\ub97c \\ud55c\\uad6d\\uc5b4\\ub85c \\ubc88\\uc5ed\\ud569\\ub2c8\\ub2e4.\\n\\n3. **\\ud14c\\uc774\\ube14 \\uc140\\uc5d0 \\ub300\\ud55c \\uc790\\uc138\\ud55c JSON \\uc9c0\\uce68**: \\uac01 \\ub370\\uc774\\ud130 \\uc140\\uc5d0 \\ub300\\ud574 \\ub370\\uc774\\ud130 \\uc140\\uc758 \\ub370\\uc774\\ud130\\uc640 \\ud5e4\\ub354 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\ubc18\\uc601\\ud558\\ub294 \\ub2e8\\uc77c JSON \\uac1c\\uccb4\\ub97c \\ub9cc\\ub4dc\\ub294 \\ubc29\\ubc95\\uc5d0 \\ub300\\ud55c \\uc9c0\\uce68\\uc744 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4.\\n\\n   - \\ud589 \\uae30\\ubc18 \\ud14c\\uc774\\ube14\\uc758 \\uacbd\\uc6b0 \\ud589 \\uba38\\ub9ac\\uae00\\uacfc \\ud574\\ub2f9 \\ud589\\uc758 \\uac01 \\uc140 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\ubc29\\ubc95\\uc744 \\uc124\\uba85\\ud569\\ub2c8\\ub2e4.\\n   - \\uc5f4 \\uae30\\ubc18 \\ud14c\\uc774\\ube14\\uc758 \\uacbd\\uc6b0 \\uc5f4 \\uba38\\ub9ac\\uae00\\uacfc \\ud574\\ub2f9 \\uc5f4\\uc758 \\uac01 \\uc140 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\ubc29\\ubc95\\uc744 \\uc124\\uba85\\ud569\\ub2c8\\ub2e4.\\n   - \\uac01 \\uc140\\uc5d0\\ub294 \\ud5e4\\ub354\\ub97c \\uae30\\ubc18\\uc73c\\ub85c \\ud0a4\\uc640 \\uc140 \\ucf58\\ud150\\uce20\\ub97c \\uae30\\ubc18\\uc73c\\ub85c \\uac12\\uc774 \\uc788\\uc5b4\\uc57c \\ud558\\uba70 \\ud5e4\\ub354\\uc640 \\uac12 \\uac04\\uc758 \\uad00\\uacc4\\uac00 \\uba85\\ud655\\ud558\\uac8c \\ubc18\\uc601\\ub418\\uc5b4\\uc57c \\ud569\\ub2c8\\ub2e4.\\n   - \\uccb4\\ud06c \\ud45c\\uc2dc, \\ud2f1 \\ud45c\\uc2dc, \\ucc44\\uc6cc\\uc9c4 \\uc0c1\\uc790 \\ub610\\ub294 \\uac12\\uc774 \\uc120\\ud0dd\\ub418\\uc5c8\\uc74c\\uc744 \\ub098\\ud0c0\\ub0b4\\ub294 \\ub2e4\\ub978 \\ud45c\\uc2dc\\uae30\\uac00 \\uc788\\ub294 \\uacbd\\uc6b0:\\n      - \\uc6d0\\ub798 \\ud14d\\uc2a4\\ud2b8: \\uc9c8\\ubb38 \\ub610\\ub294 \\ud544\\ub4dc \\ub808\\uc774\\ube14\\uc774 \\ub098\\ud0c0\\ub098\\ub294 \\ubc29\\uc2dd\\uacfc \\ud568\\uaed8 \\ubaa8\\ub4e0 \\ubc88\\ud638 \\ub610\\ub294 \\ubb38\\uc790\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\ubc29\\ubc95\\uc5d0 \\ub300\\ud55c \\uc9c0\\uce68\\uc744 \\ub9cc\\ub4ed\\ub2c8\\ub2e4.\\n      - \\ubc88\\ud638 \\ub610\\ub294 \\ubb38\\uc790\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\ubc29\\ubc95\\uc5d0 \\ub300\\ud55c \\uc9c0\\uce68\\uc744 \\ub9cc\\ub4ed\\ub2c8\\ub2e4.\\n      - \\uac01 \\uc635\\uc158\\uc744 \\ud14c\\uc774\\ube14\\uc5d0 \\uc815\\ud655\\ud558\\uac8c \\ub808\\uc774\\ube14\\ub41c \\ub300\\ub85c \\ub098\\uc5f4\\ud569\\ub2c8\\ub2e4.\\n      - \\uc120\\ud0dd \\uc0c1\\uc790\\ub97c \\ucc98\\ub9ac\\ud558\\ub294 \\ubc29\\ubc95\\uc744 \\uc124\\uba85\\ud569\\ub2c8\\ub2e4.\\n         - Yes/No \\ub610\\ub294 \\ub808\\uc774\\ube14\\uc774 \\uc9c0\\uc815\\ub41c \\uc120\\ud0dd\\uc758 \\uacbd\\uc6b0 \\\"selected\\\": \\\"No\\\"\\uc640 \\uac19\\uc774 \\uc815\\ud655\\ud55c \\uc120\\ud0dd \\ub808\\uc774\\ube14\\uc744 \\uae30\\ub85d\\ud569\\ub2c8\\ub2e4.\\n         - \\ub808\\uc774\\ube14\\uc774 \\uc5c6\\ub294 \\ub2e8\\uc77c \\uccb4\\ud06c \\uc0c1\\uc790\\uc758 \\uacbd\\uc6b0 \\uc0c1\\uc790\\uac00 \\ud45c\\uc2dc\\ub418\\uba74 \\\"true\\\" \\ub610\\ub294 \\\"false\\\"\\ub97c \\uc0ac\\uc6a9\\ud569\\ub2c8\\ub2e4.\\n         - \\ub2e4\\uc911 \\uc120\\ud0dd\\uc758 \\uacbd\\uc6b0 \\uc120\\ud0dd\\ud55c \\ubaa8\\ub4e0 \\uac12\\uc744 \\ubc30\\uc5f4\\uc5d0 \\ub098\\uc5f4\\ud569\\ub2c8\\ub2e4.\\n      - \\ubaa8\\ub4e0 \\ud14d\\uc2a4\\ud2b8\\ub97c \\ud55c\\uad6d\\uc5b4\\ub85c \\ubc88\\uc5ed\\ud569\\ub2c8\\ub2e4.\\n\\n4. **\\ud14c\\uc774\\ube14 \\ub0b4\\ub7ec\\ud2f0\\ube0c \\uc9c0\\uce68**: \\ud14c\\uc774\\ube14 \\uba38\\ub9ac\\uae00\\uacfc \\ub370\\uc774\\ud130 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\uac04\\ub2e8\\ud55c \\uc5b8\\uc5b4\\ub85c \\uc124\\uba85\\ud558\\ub294 \\uc644\\uc804\\ud55c \\ubb38\\uc7a5\\uc73c\\ub85c \\uac01 JSON \\uac1c\\uccb4\\ub97c \\uc124\\uba85\\ud558\\ub294 \\ubc29\\ubc95\\uc5d0 \\ub300\\ud55c \\uc9c0\\uce68\\uc744 \\uc81c\\uacf5\\ud569\\ub2c8\\ub2e4. \\\"JSON \\uac1c\\uccb4\\\" \\ub610\\ub294 \\\"\\ub0b4\\ub7ec\\ud2f0\\ube0c \\ud615\\uc2dd\\\"\\uacfc \\uac19\\uc740 \\uae30\\uc220 \\uc6a9\\uc5b4\\ub97c \\uc0ac\\uc6a9\\ud558\\uc9c0 \\uc54a\\ub3c4\\ub85d \\ud569\\ub2c8\\ub2e4.\\n\\n5. **\\ucd5c\\uc885 \\uad6c\\uc131**: \\uac01 \\ud14c\\uc774\\ube14 \\uc140\\uc758 \\ub0b4\\uc6a9\\uc744 \\uc124\\uba85\\ud55c \\ud6c4 JSON \\uac1c\\uccb4\\ub97c \\uc0c1\\ub2e8\\uc5d0 JSONL \\ud615\\uc2dd\\uc73c\\ub85c \\uadf8\\ub8f9\\ud654\\ud569\\ub2c8\\ub2e4.\\n   - JSONL\\uc740 \\ub4e4\\uc5ec\\uc4f0\\uae30\\ub098 \\ucd94\\uac00 \\ud615\\uc2dd\\uc744 \\ud3ec\\ud568\\ud558\\uc9c0 \\uc54a\\uc544\\uc57c \\ud569\\ub2c8\\ub2e4.\\n   - \\ub0b4\\ub7ec\\ud2f0\\ube0c \\uc124\\uba85\\uc740 \\ud558\\ub2e8\\uc5d0 \\uadf8\\ub8f9\\ud654\\ub418\\uc5b4\\uc57c \\ud558\\uba70 \\uc644\\uc804\\ud55c \\ubb38\\uc7a5\\uc73c\\ub85c \\ud14c\\uc774\\ube14\\uc758 \\ub0b4\\uc6a9\\uc744 \\uc124\\uba85\\ud574\\uc57c \\ud569\\ub2c8\\ub2e4.\\n\\n**\\uc5b8\\uc5b4 \\uc77c\\uad00\\uc131**: \\ubaa8\\ub4e0 \\uc9c0\\uce68, JSON \\ud0a4, \\uac12 \\ubc0f \\ub0b4\\ub7ec\\ud2f0\\ube0c \\uc124\\uba85\\uc740 \\ud55c\\uad6d\\uc5b4\\ub85c \\ubc88\\uc5ed\\ud574\\uc57c \\ud569\\ub2c8\\ub2e4.\\n\\n**\\uc911\\uc694 \\uc0ac\\ud56d**:\\n\\n- \\ubaa8\\ub4e0 \\uc9c0\\uce68\\uc740 \\ud14c\\uc774\\ube14 \\ud5e4\\ub354\\uc640 \\ub370\\uc774\\ud130 \\uc140 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\ucea1\\ucc98\\ud558\\ub294 \\ub370 \\uc911\\uc810\\uc744 \\ub450\\uc5b4\\uc57c \\ud569\\ub2c8\\ub2e4.\\n- \\ucd94\\uac00 \\ucee8\\ud14d\\uc2a4\\ud2b8 \\ubc0f \\uace0\\uae09 \\ud1b5\\ucc30\\ub825\\uc744 \\uc5bb\\uae30 \\uc704\\ud574 \\uc8fc\\ubcc0 \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc0ac\\uc6a9\\ud569\\ub2c8\\ub2e4.\\n- JSON \\ubc0f \\ub0b4\\ub7ec\\ud2f0\\ube0c \\uc124\\uba85 \\ubaa8\\ub450 \\ud5e4\\ub354\\uc640 \\ub370\\uc774\\ud130 \\uac04\\uc758 \\uad00\\uacc4\\ub97c \\ubc18\\uc601\\ud574\\uc57c \\ud569\\ub2c8\\ub2e4.\\n- \\ud14c\\uc774\\ube14\\uc5d0 \\uc874\\uc7ac\\ud55c\\ub2e4\\uba74 \\uc774\\ubbf8\\uc9c0\\ub098 \\uc8fc\\ubcc0 \\ud14d\\uc2a4\\ud2b8\\uc5d0\\uc11c \\ud14c\\uc774\\ube14 \\uc81c\\ubaa9\\uacfc \\ubc88\\ud638\\ub97c \\uc694\\uc57d JSON \\uac1c\\uccb4\\uc5d0 \\ucea1\\ucc98\\ud558\\ub3c4\\ub85d \\uc9c0\\uc2dc\\ud558\\ub294 \\uac83\\uc774 \\ub9e4\\uc6b0 \\uc911\\uc694\\ud569\\ub2c8\\ub2e4. \\uc804\\uccb4 \\ud14c\\uc774\\ube14 \\uc81c\\ubaa9\\uc740 \\ucf58\\ud150\\uce20 \\uc5b8\\uc5b4\\uc640 \\uac19\\uc774 `{\\\"table title\\\":\\\"TITLE\\\",\\\"table number\\\":1}`\\uc640 \\uac19\\uc740 \\ubc29\\uc2dd\\uc73c\\ub85c \\ud45c\\uc2dc\\ub429\\ub2c8\\ub2e4.\\n- \\uc9c0\\uce68\\uc774 \\uc774\\ubbf8\\uc9c0 \\ucf58\\ud150\\uce20\\ub97c \\uae30\\ubc18\\uc73c\\ub85c \\uc644\\uc804\\ud788 \\uc0ac\\uc6a9\\uc790 \\uc815\\uc758\\ub418\\ub3c4\\ub85d \\ud569\\ub2c8\\ub2e4. \\uc774 \\uc791\\uc5c5 \\uc694\\uccad\\uc758 \\uc9c0\\uce68\\uc744 \\ub2e4\\uc2dc \\uc124\\uba85\\ud558\\uac70\\ub098 \\ubc18\\ubcf5\\ud558\\uc9c0 \\ub9c8\\uc2ed\\uc2dc\\uc624. \\ub300\\uc2e0 \\uc81c\\uacf5\\ub41c \\uc774\\ubbf8\\uc9c0\\uc5d0 \\ud2b9\\uc815 \\uc751\\ub2f5\\uc744 \\uc0ac\\uc6a9\\uc790 \\uc815\\uc758\\ud569\\ub2c8\\ub2e4.\\n\\n**\\uc5b8\\uc5b4 \\uc77c\\uad00\\uc131**: \\ubaa8\\ub4e0 \\uc9c0\\uce68, JSON \\ud0a4, \\uac12 \\ubc0f \\ub0b4\\ub7ec\\ud2f0\\ube0c \\uc124\\uba85\\uc740 \\ud55c\\uad6d\\uc5b4\\ub85c \\ubc88\\uc5ed\\ud574\\uc57c \\ud569\\ub2c8\\ub2e4.\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"tool_calls\": null,\n",
      "        \"function_call\": null\n",
      "      },\n",
      "      \"provider_specific_fields\": {\n",
      "        \"stop_reason\": 106\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1070,\n",
      "    \"prompt_tokens\": 4796,\n",
      "    \"total_tokens\": 5866,\n",
      "    \"completion_tokens_details\": null,\n",
      "    \"prompt_tokens_details\": null\n",
      "  },\n",
      "  \"service_tier\": null,\n",
      "  \"prompt_logprobs\": null,\n",
      "  \"kv_transfer_params\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"KVANT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"KVANT_API_KEY not found in .env\")\n",
    "\n",
    "url = \"https://maas.ai-2.kvant.cloud/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "# payload = {\n",
    "#   \"model\": \"inference-gemma-12b-it\",\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": \"Can you describe this image please? This image is shared here. https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-0.jpg\",\n",
    "#     }\n",
    "#   ],\n",
    "#   \"temperature\": 0.7\n",
    "# }\n",
    "\n",
    "# payload = {\n",
    "#   \"model\": \"inference-gemma-12b-it\",\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [       \n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"Describe this image https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;0,0.190xh\"\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\": \"https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-1.jpg\"\n",
    "#              }\n",
    "#         }\n",
    "#       ]\n",
    "#     }\n",
    "#   ],\n",
    "#   \"temperature\": 0.7\n",
    "# }\n",
    "\n",
    "# payload = {\n",
    "#   \"model\": \"inference-gemma-12b-it\",\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [       \n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"Describe this image, https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;0,0.190xh\"\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\": \"https://hips.hearstapps.com/hmg-prod/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg?crop=1xw:0.74975xh;0,0.190xh\"\n",
    "#              }\n",
    "#         }\n",
    "#       ]\n",
    "#     }\n",
    "#   ],\n",
    "#   \"temperature\": 0.7\n",
    "# }\n",
    "\n",
    "payload = {\n",
    "  \"model\": \"inference-gemma-12b-it\",\n",
    "  \"messages\": [\n",
    "        {\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"You are a helpful assistant specialized in creating instructions for analyzing and transforming table images into JSON and narrative text. Your task is to analyze the provided image of a table and generate custom instructions that explain how to structure the content of the table into JSON and narrative text. Your output should include **only instructions**. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\nThe most important part of your task is to ensure that every single **relationship** between the cells, headers, and overall structure is **captured accurately**. It is not enough to convert the table cells into JSON individually; the **relationships between the data** (such as row and column headers, data groupings, and interactions) must be reflected in the final JSON.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **Analyze the Table Structure**: **Identify and list all visible components** of the table. These could include the table title, table number, column headers, row headers, data cells, or any other visual elements.\\\\n  - Focus on identifying the **relationships** between headers and data cells. For example:\\\\n    - If the table has column and row headers, describe how the headers relate to the values in each cell.\\\\n    - If cells are grouped or have shared characteristics (e.g., by row or column), describe how these groups should be represented in JSON.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\\\"Yes/No\\\\\\\", \\\\\\\"Male/Female\\\\\\\", \\\\\\\"Option A/Option B/Option C\\\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\\\"selected\\\\\\\": \\\\\\\"No\\\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\\\"true\\\\\\\" or \\\\\\\"false\\\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table's visible content, avoiding assumptions.\\\\n\\\\n2. **Summary JSON Instructions**: Create detailed instructions for constructing a **summary JSON object** that captures high-level information, such as the table title, number, and main topics or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis, if they highlight key insights (e.g., trends across rows or columns). For example, you could add a \\\\\\\"trends\\\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - Include the **table title and number** if they exist in the image or surrounding text. It is critical that the title and number be accurately represented in the summary JSON object.\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\\\"figure\\\\\\\" call it \\\\\\\"figure_title\\\\\\\" and  \\\\\\\"figure_number\\\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. It  *must be customized* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\\\"table_title\\\\\\\":\\\\\\\"Example Table\\\\\\\",\\\\\\\"table_number\\\\\\\":5,\\\\\\\"description\\\\\\\":\\\\\\\"X\\\\\\\",\\\\\\\"trends\\\\\\\":\\\\\\\"Q\\\\\\\"}\\\\n```\\\\n  - If the table lacks a title or number, make it clear in the instructions that the JSON should reflect that it is missing.\\\\n\\\\n3. **Detailed JSON for Table Cells**: For each data cell in the table, provide instructions on how to create a **single JSON object** that reflects both the data in the cell and the **relationship** between that data and its headers.\\\\n  - If the table is organized in rows, describe how to capture the relationships between the **row header** and each corresponding cell in that row. For example:\\\\n```\\\\n{\\\\\\\"header_1\\\\\\\":\\\\\\\"Value_1\\\\\\\",\\\\\\\"header_2\\\\\\\":\\\\\\\"Value_2\\\\\\\"}\\\\n```\\\\n  - If the table is organized in columns, describe how to capture the relationships between the **column header** and each cell in that column.\\\\n  - **Ensure that every cell has both a key (based on headers) and a value (based on the cell's content)**, and the relationships between headers and values are reflected clearly.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n4. **Table Narrative Instructions**: Provide instructions for narrating the contents of the JSON into **complete sentences** that describe the relationships between the cells.\\\\n  - The narrative must clearly explain the **contents** of the table and the **relationships** between headers and data in simple language.\\\\n  - Do not use technical terms like \\\\\\\"JSON object\\\\\\\" or \\\\\\\"narrative format\\\\\\\"; simply describe the table data in sentence form.\\\\n  - **Example of a narrative**:\\\\n    - \\\\\\\"In this table, the category is 'Food,' the amount is '100,' and the date is '01-01-2024.' Another entry in the table shows that the category is 'Transport,' the amount is '50,' and the date is '01-02-2024.'\\\\\\\"\\\\n\\\\n5. **Final Organization**: After describing each table cell's content, instruct that the JSON objects should be grouped at the top into a **JSONL format** without indentation or extra formatting.\\\\n  - The narrative description should be grouped at the bottom, explaining the JSON content in full sentences.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in Korean**: Ensure that all JSON keys, values, and narrative text are written in Korean, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.\",\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            ],\n",
    "            \"role\": \"system\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": \"Here is the text that is on the same page as the table. It may or may not be relevant to the table:\\\\n\\\\n국제 금융 센터\\\\nIssue Analysis\\\\n[ 위험 요인 ] 고금리 장기화 중동 불안 잠재 달러 강세 심화 가능성 상업용 부동산\\\\n 위험 등 이 복합 작용 한다면 경기 회복 기대감 및 투자 심리 가 추가적으로 악화 할 가능성\\\\n ● 고금리 장기화 디스인플레이션 지연 으로 美 연준 의 금리 인하 기대감 이 약해지고 , 금리 인하\\\\n 시기 를 가늠 중인 중앙 은행 들 도 美 연준 과 통화 정책 격차 의 부작용 을 고려 하면서 주요국\\\\n 전반 에서 고금리 기조 장기화 , 수요 · 투자 위축 , 신용 악화 등 부작용 우려\\\\nㅇ ( 현황 ) 최근 미국 등 주요국 의 물가 가 반등 하면서 디스인플레이션 경로 가 예상 보다\\\\n 험난한 경로 ( bumpy road to disinflation ) 로 진행\\\\n-\\\\n-\\\\n미국 소비자 물가 상승률 ( 전월비 ) 이 금년 1 분기 중 0.3 ~ 0.4 % 를 기록 하여 전년 4 분기\\\\n0.1 ~ 0.2 % 에 비해 크게 높아진 데다 전년 동월비 기준 으로 도 3 개월 째 반등 \\\\u003c 표 1 \\\\u003e\\\\n유로존 소비자 물가 상승률 ( 전월비 ) 이 금년 2,3 월 에 각각 0.6 % , 0.8 % 로 크게 높아진 가운데 특히\\\\n 서비스 물가 가 전년 동월비 기준 으로 4 % 를 자 속상 하며 여전히 인플레이션 목표치 와 거리\\\\nㅇ ( 평가 ) 디스인플레이션 후퇴 로 주요 중앙 은행 들이 단기간 내 강하게 금리 인하 를\\\\n 시행 하는 것에 대한 부담 이 커짐 에 따라 경기 회복 추세 에도 부정적인 영향\\\\n\\\\t|\\\\t\\\\u003c 표 1 \\\\u003e OIS 에 반영된 미국 · 유로존 영국 의 금년 말 기준 금리 수준 전망치 변화\\\\n구분\\\\t|\\\\t현 기준 금리 수준 '24 년 1 월말 '24 년 2 월말 '24 년 3 월말 24 년 4 월말\\\\n\\\\t|\\\\t4.02 4.65 4.80 5.16\\\\n미국 ( Fed )\\\\t|\\\\t5.50\\\\n\\\\t|\\\\t( 5.9 ) ( 3.4 ) ( 2.8 ) ( 1.4 )\\\\n\\\\t|\\\\t2.90 3.59 3.61 3.78\\\\n유로존 ( ECB )\\\\t|\\\\t4.50\\\\n\\\\t|\\\\t( 6.4 ) ( 3.6 ) ( 3.6 ) ( 2.9 )\\\\n\\\\t|\\\\t4.12 4.62 4.52 4.81\\\\n영국 ( BOE )\\\\t|\\\\t5.25\\\\n\\\\t|\\\\t( 4.5 ) ( 2.5 ) ( 2.9 ) ( 1.8 )\\\\n주 :( ) 안은 baby step ( -0.25 % p ) 기준 금리 인하 횟수\\\\n자료 : Bloomberg\\\\n・ 연준 의 HAL ( Higher for Longer ) 로 ECB 를 포함한 여타 중앙 은행 들의 금리 인하 폭 이\\\\n 줄어들고 시기 도 이연 될 가능성\\\\nㅇ ( 영향 ) 고금리 기조 장기화 시 경제 주체 들의 수요 · 투자 위축 , 신용 악화 우려 , 금리\\\\n 하향 을 기대 했던 투자 자금 이탈 과 자산 가격 조정 등 경제 · 금융 부작용 이 지속될 소지\\\\n\\\\u003c 그림 3 \\\\u003e 연말 까지 정책 금리 인하 폭 확률 추이\\\\n\\\\t|\\\\t\\\\u003c 표 2 \\\\u003e 주요국 소비자 물가 증감율 추이\\\\n구분\\\\t|\\\\t'23 .10 '23 .11 23.12 24.1 월 24.2 월 '24 .3\\\\n미국 CPI MoM\\\\t|\\\\t0.1 0.2 0.2 0.3 0.4 0.4\\\\n미국 CPI YoY\\\\t|\\\\t3.2 3.1 3.4 3.1 3.2 3.5\\\\n미국 근원 PCE MoM\\\\t|\\\\t0.1 0.1 0.2 0.5 0.3\\\\n유로존 CPI MOM\\\\t|\\\\t0.1 -0.6 0.2 -0.4 0.6 0.8\\\\n유로존 CPI YoY\\\\t|\\\\t2.9 2.4 2.9 2.8 2.6 2.4\\\\n영국 CPI MoM\\\\t|\\\\t0.0 -0.2 0.4 -0.6 0.6 0.6\\\\n영국 CPI YoY\\\\t|\\\\t4.6 3.9 4.0 4.0 3.4 3.2\\\\n50\\\\n100bp 인하\\\\n-50bp 인하\\\\n• 75bp 인하\\\\n-25bp 인하\\\\n동결\\\\n40\\\\n30\\\\n20\\\\n10\\\\n0\\\\n03.01\\\\n03.16\\\\n03.31\\\\n04.15\\\\n자료 : Bloomberg\\\\n자료 : CME FedWatch\\\\nKCIF\",\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                {\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/3.jpg\"\n",
    "                    },\n",
    "                    \"type\": \"image_url\"\n",
    "                },\n",
    "                {\n",
    "                    \"text\": \"Here is an image of a table. Your task is to analyze the image and provide **custom instructions** on how to convert the table into JSON and narrative text, ensuring that both the **content** and the **relationships** between the elements in the table are captured accurately. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n- **Identify and list all components**: Identify the table title, table number, column headers, row headers, data cells, and layout of information.\\\\n  - Use any surrounding text to help clarify the structure and purpose of the table.\\\\n  - Focus on the relationships between the headers and the data in each cell. For example, how does each column header relate to the values in that column? How do row headers correspond to the data in the rows?\\\\n  - Identify how the table lays out information: in columns, rows, or some combination.\\\\n\\\\n- **Create Summary JSON**: After analyzing the table, provide instructions for creating a **summary JSON object** that captures high-level information, such as the table title, number, and main headers. This should also include a description of the table's purpose, main topics, or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image, based on your analysis, only if they convey key insights (e.g., recurring patterns or trends across rows or columns). For example, you could add a \\\\\\\"trends\\\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - If a table title or table number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\\\"figure\\\\\\\" call it \\\\\\\"figure_title\\\\\\\" and  \\\\\\\"figure_number\\\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\\\"table_title\\\\\\\":\\\\\\\"Example Table\\\\\\\",\\\\\\\"table_number\\\\\\\":5,\\\\\\\"description\\\\\\\":\\\\\\\"X\\\\\\\",\\\\\\\"trends\\\\\\\":\\\\\\\"Q\\\\\\\"}\\\\n```\\\\n\\\\n- **Create Detailed JSON for Table Cells**: Provide instructions on how to convert each cell into a **single JSON object** that reflects both the **data in the cell** and the **relationship between the headers and data**.\\\\n  - For row-based tables, explain how to capture the relationships between row headers and each cell.\\\\n  - For column-based tables, explain how to capture the relationships between column headers and each cell.\\\\n  - It is **vital** that every cell has both a **key** (based on headers) and a **value** (based on cell content).\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\\\"Yes/No\\\\\\\", \\\\\\\"Male/Female\\\\\\\", \\\\\\\"Option A/Option B/Option C\\\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\\\"selected\\\\\\\": \\\\\\\"No\\\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\\\"true\\\\\\\" or \\\\\\\"false\\\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table's visible content, avoiding assumptions.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n- **Narrate the JSON**: Provide instructions for how to narrate each JSON object into a complete sentence, explaining the relationships between the table's headers and data in simple language.\\\\n  - Ensure that the narrative text is written without referring to technical terms like \\\\\\\"JSON object\\\\\\\" or \\\\\\\"narrative format.\\\\\\\"\\\\n\\\\n- **Final JSONL and Narrative Instructions**: Group the JSON objects together at the top in a JSONL format (without indentation).\\\\n  - The narrative text should be grouped at the bottom and should describe the contents of the table in full sentences.\\\\n\\\\n**Important Notes**:\\\\n\\\\n- It is crucial that your instructions focus on capturing **relationships between table headers and data cells** rather than just converting cells individually.\\\\n- Use the surrounding text to capture additional context and high-level insights.\\\\n- Make sure that both the JSON and the narrative descriptions reflect the **relationships** between the elements, such as how headers correspond to cell values.\\\\n- It is absolutely vital that you create instructions to capture BOTH the table title and number, if they exist in the image or surrounding text, in the summary JSON object. The entire table title must be captured IN THE LANGUAGE OF THE CONTENT like this `{\\\\\\\"table title\\\\\\\":\\\\\\\"TITLE\\\\\\\",\\\\\\\"table number\\\\\\\":1}`, except translate \\\\\\\"table title\\\\\\\" and \\\\\\\"table number\\\\\\\" into the language of the content.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\nPlease make it clear that the JSONL should not contain indentation, formatting, or new lines. \\\\nPlease provide the LLM prompt without additional commentary or notes.\\\\nRemember, it is ABSOLUTELY CRITICAL you capture ALL of the original information conveyed in the table.\\\\n\\\\nHere is the image of what I think is a table. It may or may not include column and row headers.\",\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                {\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-0.jpg\"\n",
    "                    },\n",
    "                    \"type\": \"image_url\"\n",
    "                }\n",
    "            ],\n",
    "            \"role\": \"user\"\n",
    "        }\n",
    "    ],\n",
    "  \"temperature\": 0.7\n",
    "}\n",
    " \n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload, timeout=300)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "\n",
    "try:\n",
    "    data = response.json()\n",
    "    print(json.dumps(data, indent=2))\n",
    "except ValueError:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2891b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "{'max_tokens': 4000, 'messages': [{'content': [{'text': 'You are a helpful assistant specialized in creating instructions for analyzing and transforming table images into JSON and narrative text. Your task is to analyze the provided image of a table and generate custom instructions that explain how to structure the content of the table into JSON and narrative text. Your output should include **only instructions**. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\nThe most important part of your task is to ensure that every single **relationship** between the cells, headers, and overall structure is **captured accurately**. It is not enough to convert the table cells into JSON individually; the **relationships between the data** (such as row and column headers, data groupings, and interactions) must be reflected in the final JSON.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **Analyze the Table Structure**: **Identify and list all visible components** of the table. These could include the table title, table number, column headers, row headers, data cells, or any other visual elements.\\\\n  - Focus on identifying the **relationships** between headers and data cells. For example:\\\\n    - If the table has column and row headers, describe how the headers relate to the values in each cell.\\\\n    - If cells are grouped or have shared characteristics (e.g., by row or column), describe how these groups should be represented in JSON.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n\\\\n2. **Summary JSON Instructions**: Create detailed instructions for constructing a **summary JSON object** that captures high-level information, such as the table title, number, and main topics or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis, if they highlight key insights (e.g., trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - Include the **table title and number** if they exist in the image or surrounding text. It is critical that the title and number be accurately represented in the summary JSON object.\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. It  *must be customized* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n  - If the table lacks a title or number, make it clear in the instructions that the JSON should reflect that it is missing.\\\\n\\\\n3. **Detailed JSON for Table Cells**: For each data cell in the table, provide instructions on how to create a **single JSON object** that reflects both the data in the cell and the **relationship** between that data and its headers.\\\\n  - If the table is organized in rows, describe how to capture the relationships between the **row header** and each corresponding cell in that row. For example:\\\\n```\\\\n{\\\\\"header_1\\\\\":\\\\\"Value_1\\\\\",\\\\\"header_2\\\\\":\\\\\"Value_2\\\\\"}\\\\n```\\\\n  - If the table is organized in columns, describe how to capture the relationships between the **column header** and each cell in that column.\\\\n  - **Ensure that every cell has both a key (based on headers) and a value (based on the cell\\'s content)**, and the relationships between headers and values are reflected clearly.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n4. **Table Narrative Instructions**: Provide instructions for narrating the contents of the JSON into **complete sentences** that describe the relationships between the cells.\\\\n  - The narrative must clearly explain the **contents** of the table and the **relationships** between headers and data in simple language.\\\\n  - Do not use technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format\\\\\"; simply describe the table data in sentence form.\\\\n  - **Example of a narrative**:\\\\n    - \\\\\"In this table, the category is \\'Food,\\' the amount is \\'100,\\' and the date is \\'01-01-2024.\\' Another entry in the table shows that the category is \\'Transport,\\' the amount is \\'50,\\' and the date is \\'01-02-2024.\\'\\\\\"\\\\n\\\\n5. **Final Organization**: After describing each table cell\\'s content, instruct that the JSON objects should be grouped at the top into a **JSONL format** without indentation or extra formatting.\\\\n  - The narrative description should be grouped at the bottom, explaining the JSON content in full sentences.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in Korean**: Ensure that all JSON keys, values, and narrative text are written in Korean, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': \"Here is the text that is on the same page as the table. It may or may not be relevant to the table:\\\\n\\\\n국제 금융 센터\\\\nIssue Analysis\\\\n[ 위험 요인 ] 고금리 장기화 중동 불안 잠재 달러 강세 심화 가능성 상업용 부동산\\\\n 위험 등 이 복합 작용 한다면 경기 회복 기대감 및 투자 심리 가 추가적으로 악화 할 가능성\\\\n ● 고금리 장기화 디스인플레이션 지연 으로 美 연준 의 금리 인하 기대감 이 약해지고 , 금리 인하\\\\n 시기 를 가늠 중인 중앙 은행 들 도 美 연준 과 통화 정책 격차 의 부작용 을 고려 하면서 주요국\\\\n 전반 에서 고금리 기조 장기화 , 수요 · 투자 위축 , 신용 악화 등 부작용 우려\\\\nㅇ ( 현황 ) 최근 미국 등 주요국 의 물가 가 반등 하면서 디스인플레이션 경로 가 예상 보다\\\\n 험난한 경로 ( bumpy road to disinflation ) 로 진행\\\\n-\\\\n-\\\\n미국 소비자 물가 상승률 ( 전월비 ) 이 금년 1 분기 중 0.3 ~ 0.4 % 를 기록 하여 전년 4 분기\\\\n0.1 ~ 0.2 % 에 비해 크게 높아진 데다 전년 동월비 기준 으로 도 3 개월 째 반등 \\\\u003c 표 1 \\\\u003e\\\\n유로존 소비자 물가 상승률 ( 전월비 ) 이 금년 2,3 월 에 각각 0.6 % , 0.8 % 로 크게 높아진 가운데 특히\\\\n 서비스 물가 가 전년 동월비 기준 으로 4 % 를 자 속상 하며 여전히 인플레이션 목표치 와 거리\\\\nㅇ ( 평가 ) 디스인플레이션 후퇴 로 주요 중앙 은행 들이 단기간 내 강하게 금리 인하 를\\\\n 시행 하는 것에 대한 부담 이 커짐 에 따라 경기 회복 추세 에도 부정적인 영향\\\\n\\\\t|\\\\t\\\\u003c 표 1 \\\\u003e OIS 에 반영된 미국 · 유로존 영국 의 금년 말 기준 금리 수준 전망치 변화\\\\n구분\\\\t|\\\\t현 기준 금리 수준 '24 년 1 월말 '24 년 2 월말 '24 년 3 월말 24 년 4 월말\\\\n\\\\t|\\\\t4.02 4.65 4.80 5.16\\\\n미국 ( Fed )\\\\t|\\\\t5.50\\\\n\\\\t|\\\\t( 5.9 ) ( 3.4 ) ( 2.8 ) ( 1.4 )\\\\n\\\\t|\\\\t2.90 3.59 3.61 3.78\\\\n유로존 ( ECB )\\\\t|\\\\t4.50\\\\n\\\\t|\\\\t( 6.4 ) ( 3.6 ) ( 3.6 ) ( 2.9 )\\\\n\\\\t|\\\\t4.12 4.62 4.52 4.81\\\\n영국 ( BOE )\\\\t|\\\\t5.25\\\\n\\\\t|\\\\t( 4.5 ) ( 2.5 ) ( 2.9 ) ( 1.8 )\\\\n주 :( ) 안은 baby step ( -0.25 % p ) 기준 금리 인하 횟수\\\\n자료 : Bloomberg\\\\n・ 연준 의 HAL ( Higher for Longer ) 로 ECB 를 포함한 여타 중앙 은행 들의 금리 인하 폭 이\\\\n 줄어들고 시기 도 이연 될 가능성\\\\nㅇ ( 영향 ) 고금리 기조 장기화 시 경제 주체 들의 수요 · 투자 위축 , 신용 악화 우려 , 금리\\\\n 하향 을 기대 했던 투자 자금 이탈 과 자산 가격 조정 등 경제 · 금융 부작용 이 지속될 소지\\\\n\\\\u003c 그림 3 \\\\u003e 연말 까지 정책 금리 인하 폭 확률 추이\\\\n\\\\t|\\\\t\\\\u003c 표 2 \\\\u003e 주요국 소비자 물가 증감율 추이\\\\n구분\\\\t|\\\\t'23 .10 '23 .11 23.12 24.1 월 24.2 월 '24 .3\\\\n미국 CPI MoM\\\\t|\\\\t0.1 0.2 0.2 0.3 0.4 0.4\\\\n미국 CPI YoY\\\\t|\\\\t3.2 3.1 3.4 3.1 3.2 3.5\\\\n미국 근원 PCE MoM\\\\t|\\\\t0.1 0.1 0.2 0.5 0.3\\\\n유로존 CPI MOM\\\\t|\\\\t0.1 -0.6 0.2 -0.4 0.6 0.8\\\\n유로존 CPI YoY\\\\t|\\\\t2.9 2.4 2.9 2.8 2.6 2.4\\\\n영국 CPI MoM\\\\t|\\\\t0.0 -0.2 0.4 -0.6 0.6 0.6\\\\n영국 CPI YoY\\\\t|\\\\t4.6 3.9 4.0 4.0 3.4 3.2\\\\n50\\\\n100bp 인하\\\\n-50bp 인하\\\\n• 75bp 인하\\\\n-25bp 인하\\\\n동결\\\\n40\\\\n30\\\\n20\\\\n10\\\\n0\\\\n03.01\\\\n03.16\\\\n03.31\\\\n04.15\\\\n자료 : Bloomberg\\\\n자료 : CME FedWatch\\\\nKCIF\", 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/3.jpg'}, 'type': 'image_url'}, {'text': 'Here is an image of a table. Your task is to analyze the image and provide **custom instructions** on how to convert the table into JSON and narrative text, ensuring that both the **content** and the **relationships** between the elements in the table are captured accurately. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n- **Identify and list all components**: Identify the table title, table number, column headers, row headers, data cells, and layout of information.\\\\n  - Use any surrounding text to help clarify the structure and purpose of the table.\\\\n  - Focus on the relationships between the headers and the data in each cell. For example, how does each column header relate to the values in that column? How do row headers correspond to the data in the rows?\\\\n  - Identify how the table lays out information: in columns, rows, or some combination.\\\\n\\\\n- **Create Summary JSON**: After analyzing the table, provide instructions for creating a **summary JSON object** that captures high-level information, such as the table title, number, and main headers. This should also include a description of the table\\'s purpose, main topics, or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image, based on your analysis, only if they convey key insights (e.g., recurring patterns or trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - If a table title or table number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n\\\\n- **Create Detailed JSON for Table Cells**: Provide instructions on how to convert each cell into a **single JSON object** that reflects both the **data in the cell** and the **relationship between the headers and data**.\\\\n  - For row-based tables, explain how to capture the relationships between row headers and each cell.\\\\n  - For column-based tables, explain how to capture the relationships between column headers and each cell.\\\\n  - It is **vital** that every cell has both a **key** (based on headers) and a **value** (based on cell content).\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n- **Narrate the JSON**: Provide instructions for how to narrate each JSON object into a complete sentence, explaining the relationships between the table\\'s headers and data in simple language.\\\\n  - Ensure that the narrative text is written without referring to technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format.\\\\\"\\\\n\\\\n- **Final JSONL and Narrative Instructions**: Group the JSON objects together at the top in a JSONL format (without indentation).\\\\n  - The narrative text should be grouped at the bottom and should describe the contents of the table in full sentences.\\\\n\\\\n**Important Notes**:\\\\n\\\\n- It is crucial that your instructions focus on capturing **relationships between table headers and data cells** rather than just converting cells individually.\\\\n- Use the surrounding text to capture additional context and high-level insights.\\\\n- Make sure that both the JSON and the narrative descriptions reflect the **relationships** between the elements, such as how headers correspond to cell values.\\\\n- It is absolutely vital that you create instructions to capture BOTH the table title and number, if they exist in the image or surrounding text, in the summary JSON object. The entire table title must be captured IN THE LANGUAGE OF THE CONTENT like this `{\\\\\"table title\\\\\":\\\\\"TITLE\\\\\",\\\\\"table number\\\\\":1}`, except translate \\\\\"table title\\\\\" and \\\\\"table number\\\\\" into the language of the content.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\nPlease make it clear that the JSONL should not contain indentation, formatting, or new lines. \\\\nPlease provide the LLM prompt without additional commentary or notes.\\\\nRemember, it is ABSOLUTELY CRITICAL you capture ALL of the original information conveyed in the table.\\\\n\\\\nHere is the image of what I think is a table. It may or may not include column and row headers.', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-1.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'inference-gemma-12b-it', 'response_format': {'type': 'text'}, 'stop': ['==='], 'temperature': 0.3, 'top_p': 0.7}\n",
      "----\n",
      "Finished api-req3.json -> 200 (12.897s)\n",
      "----\n",
      "{'max_tokens': 4000, 'messages': [{'content': [{'text': 'You are a helpful assistant specialized in creating instructions for analyzing and transforming table images into JSON and narrative text. Your task is to analyze the provided image of a table and generate custom instructions that explain how to structure the content of the table into JSON and narrative text. Your output should include **only instructions**. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\nThe most important part of your task is to ensure that every single **relationship** between the cells, headers, and overall structure is **captured accurately**. It is not enough to convert the table cells into JSON individually; the **relationships between the data** (such as row and column headers, data groupings, and interactions) must be reflected in the final JSON.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **Analyze the Table Structure**: **Identify and list all visible components** of the table. These could include the table title, table number, column headers, row headers, data cells, or any other visual elements.\\\\n  - Focus on identifying the **relationships** between headers and data cells. For example:\\\\n    - If the table has column and row headers, describe how the headers relate to the values in each cell.\\\\n    - If cells are grouped or have shared characteristics (e.g., by row or column), describe how these groups should be represented in JSON.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n\\\\n2. **Summary JSON Instructions**: Create detailed instructions for constructing a **summary JSON object** that captures high-level information, such as the table title, number, and main topics or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis, if they highlight key insights (e.g., trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - Include the **table title and number** if they exist in the image or surrounding text. It is critical that the title and number be accurately represented in the summary JSON object.\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. It  *must be customized* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n  - If the table lacks a title or number, make it clear in the instructions that the JSON should reflect that it is missing.\\\\n\\\\n3. **Detailed JSON for Table Cells**: For each data cell in the table, provide instructions on how to create a **single JSON object** that reflects both the data in the cell and the **relationship** between that data and its headers.\\\\n  - If the table is organized in rows, describe how to capture the relationships between the **row header** and each corresponding cell in that row. For example:\\\\n```\\\\n{\\\\\"header_1\\\\\":\\\\\"Value_1\\\\\",\\\\\"header_2\\\\\":\\\\\"Value_2\\\\\"}\\\\n```\\\\n  - If the table is organized in columns, describe how to capture the relationships between the **column header** and each cell in that column.\\\\n  - **Ensure that every cell has both a key (based on headers) and a value (based on the cell\\'s content)**, and the relationships between headers and values are reflected clearly.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n4. **Table Narrative Instructions**: Provide instructions for narrating the contents of the JSON into **complete sentences** that describe the relationships between the cells.\\\\n  - The narrative must clearly explain the **contents** of the table and the **relationships** between headers and data in simple language.\\\\n  - Do not use technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format\\\\\"; simply describe the table data in sentence form.\\\\n  - **Example of a narrative**:\\\\n    - \\\\\"In this table, the category is \\'Food,\\' the amount is \\'100,\\' and the date is \\'01-01-2024.\\' Another entry in the table shows that the category is \\'Transport,\\' the amount is \\'50,\\' and the date is \\'01-02-2024.\\'\\\\\"\\\\n\\\\n5. **Final Organization**: After describing each table cell\\'s content, instruct that the JSON objects should be grouped at the top into a **JSONL format** without indentation or extra formatting.\\\\n  - The narrative description should be grouped at the bottom, explaining the JSON content in full sentences.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in Korean**: Ensure that all JSON keys, values, and narrative text are written in Korean, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': \"Here is the text that is on the same page as the table. It may or may not be relevant to the table:\\\\n\\\\n국제 금융 센터\\\\nIssue Analysis\\\\n[ 위험 요인 ] 고금리 장기화 중동 불안 잠재 달러 강세 심화 가능성 상업용 부동산\\\\n 위험 등 이 복합 작용 한다면 경기 회복 기대감 및 투자 심리 가 추가적으로 악화 할 가능성\\\\n ● 고금리 장기화 디스인플레이션 지연 으로 美 연준 의 금리 인하 기대감 이 약해지고 , 금리 인하\\\\n 시기 를 가늠 중인 중앙 은행 들 도 美 연준 과 통화 정책 격차 의 부작용 을 고려 하면서 주요국\\\\n 전반 에서 고금리 기조 장기화 , 수요 · 투자 위축 , 신용 악화 등 부작용 우려\\\\nㅇ ( 현황 ) 최근 미국 등 주요국 의 물가 가 반등 하면서 디스인플레이션 경로 가 예상 보다\\\\n 험난한 경로 ( bumpy road to disinflation ) 로 진행\\\\n-\\\\n-\\\\n미국 소비자 물가 상승률 ( 전월비 ) 이 금년 1 분기 중 0.3 ~ 0.4 % 를 기록 하여 전년 4 분기\\\\n0.1 ~ 0.2 % 에 비해 크게 높아진 데다 전년 동월비 기준 으로 도 3 개월 째 반등 \\\\u003c 표 1 \\\\u003e\\\\n유로존 소비자 물가 상승률 ( 전월비 ) 이 금년 2,3 월 에 각각 0.6 % , 0.8 % 로 크게 높아진 가운데 특히\\\\n 서비스 물가 가 전년 동월비 기준 으로 4 % 를 자 속상 하며 여전히 인플레이션 목표치 와 거리\\\\nㅇ ( 평가 ) 디스인플레이션 후퇴 로 주요 중앙 은행 들이 단기간 내 강하게 금리 인하 를\\\\n 시행 하는 것에 대한 부담 이 커짐 에 따라 경기 회복 추세 에도 부정적인 영향\\\\n\\\\t|\\\\t\\\\u003c 표 1 \\\\u003e OIS 에 반영된 미국 · 유로존 영국 의 금년 말 기준 금리 수준 전망치 변화\\\\n구분\\\\t|\\\\t현 기준 금리 수준 '24 년 1 월말 '24 년 2 월말 '24 년 3 월말 24 년 4 월말\\\\n\\\\t|\\\\t4.02 4.65 4.80 5.16\\\\n미국 ( Fed )\\\\t|\\\\t5.50\\\\n\\\\t|\\\\t( 5.9 ) ( 3.4 ) ( 2.8 ) ( 1.4 )\\\\n\\\\t|\\\\t2.90 3.59 3.61 3.78\\\\n유로존 ( ECB )\\\\t|\\\\t4.50\\\\n\\\\t|\\\\t( 6.4 ) ( 3.6 ) ( 3.6 ) ( 2.9 )\\\\n\\\\t|\\\\t4.12 4.62 4.52 4.81\\\\n영국 ( BOE )\\\\t|\\\\t5.25\\\\n\\\\t|\\\\t( 4.5 ) ( 2.5 ) ( 2.9 ) ( 1.8 )\\\\n주 :( ) 안은 baby step ( -0.25 % p ) 기준 금리 인하 횟수\\\\n자료 : Bloomberg\\\\n・ 연준 의 HAL ( Higher for Longer ) 로 ECB 를 포함한 여타 중앙 은행 들의 금리 인하 폭 이\\\\n 줄어들고 시기 도 이연 될 가능성\\\\nㅇ ( 영향 ) 고금리 기조 장기화 시 경제 주체 들의 수요 · 투자 위축 , 신용 악화 우려 , 금리\\\\n 하향 을 기대 했던 투자 자금 이탈 과 자산 가격 조정 등 경제 · 금융 부작용 이 지속될 소지\\\\n\\\\u003c 그림 3 \\\\u003e 연말 까지 정책 금리 인하 폭 확률 추이\\\\n\\\\t|\\\\t\\\\u003c 표 2 \\\\u003e 주요국 소비자 물가 증감율 추이\\\\n구분\\\\t|\\\\t'23 .10 '23 .11 23.12 24.1 월 24.2 월 '24 .3\\\\n미국 CPI MoM\\\\t|\\\\t0.1 0.2 0.2 0.3 0.4 0.4\\\\n미국 CPI YoY\\\\t|\\\\t3.2 3.1 3.4 3.1 3.2 3.5\\\\n미국 근원 PCE MoM\\\\t|\\\\t0.1 0.1 0.2 0.5 0.3\\\\n유로존 CPI MOM\\\\t|\\\\t0.1 -0.6 0.2 -0.4 0.6 0.8\\\\n유로존 CPI YoY\\\\t|\\\\t2.9 2.4 2.9 2.8 2.6 2.4\\\\n영국 CPI MoM\\\\t|\\\\t0.0 -0.2 0.4 -0.6 0.6 0.6\\\\n영국 CPI YoY\\\\t|\\\\t4.6 3.9 4.0 4.0 3.4 3.2\\\\n50\\\\n100bp 인하\\\\n-50bp 인하\\\\n• 75bp 인하\\\\n-25bp 인하\\\\n동결\\\\n40\\\\n30\\\\n20\\\\n10\\\\n0\\\\n03.01\\\\n03.16\\\\n03.31\\\\n04.15\\\\n자료 : Bloomberg\\\\n자료 : CME FedWatch\\\\nKCIF\", 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/3.jpg'}, 'type': 'image_url'}, {'text': 'Here is an image of a table. Your task is to analyze the image and provide **custom instructions** on how to convert the table into JSON and narrative text, ensuring that both the **content** and the **relationships** between the elements in the table are captured accurately. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n- **Identify and list all components**: Identify the table title, table number, column headers, row headers, data cells, and layout of information.\\\\n  - Use any surrounding text to help clarify the structure and purpose of the table.\\\\n  - Focus on the relationships between the headers and the data in each cell. For example, how does each column header relate to the values in that column? How do row headers correspond to the data in the rows?\\\\n  - Identify how the table lays out information: in columns, rows, or some combination.\\\\n\\\\n- **Create Summary JSON**: After analyzing the table, provide instructions for creating a **summary JSON object** that captures high-level information, such as the table title, number, and main headers. This should also include a description of the table\\'s purpose, main topics, or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image, based on your analysis, only if they convey key insights (e.g., recurring patterns or trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - If a table title or table number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n\\\\n- **Create Detailed JSON for Table Cells**: Provide instructions on how to convert each cell into a **single JSON object** that reflects both the **data in the cell** and the **relationship between the headers and data**.\\\\n  - For row-based tables, explain how to capture the relationships between row headers and each cell.\\\\n  - For column-based tables, explain how to capture the relationships between column headers and each cell.\\\\n  - It is **vital** that every cell has both a **key** (based on headers) and a **value** (based on cell content).\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n- **Narrate the JSON**: Provide instructions for how to narrate each JSON object into a complete sentence, explaining the relationships between the table\\'s headers and data in simple language.\\\\n  - Ensure that the narrative text is written without referring to technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format.\\\\\"\\\\n\\\\n- **Final JSONL and Narrative Instructions**: Group the JSON objects together at the top in a JSONL format (without indentation).\\\\n  - The narrative text should be grouped at the bottom and should describe the contents of the table in full sentences.\\\\n\\\\n**Important Notes**:\\\\n\\\\n- It is crucial that your instructions focus on capturing **relationships between table headers and data cells** rather than just converting cells individually.\\\\n- Use the surrounding text to capture additional context and high-level insights.\\\\n- Make sure that both the JSON and the narrative descriptions reflect the **relationships** between the elements, such as how headers correspond to cell values.\\\\n- It is absolutely vital that you create instructions to capture BOTH the table title and number, if they exist in the image or surrounding text, in the summary JSON object. The entire table title must be captured IN THE LANGUAGE OF THE CONTENT like this `{\\\\\"table title\\\\\":\\\\\"TITLE\\\\\",\\\\\"table number\\\\\":1}`, except translate \\\\\"table title\\\\\" and \\\\\"table number\\\\\" into the language of the content.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\nPlease make it clear that the JSONL should not contain indentation, formatting, or new lines. \\\\nPlease provide the LLM prompt without additional commentary or notes.\\\\nRemember, it is ABSOLUTELY CRITICAL you capture ALL of the original information conveyed in the table.\\\\n\\\\nHere is the image of what I think is a table. It may or may not include column and row headers.', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-0.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'inference-gemma-12b-it', 'response_format': {'type': 'text'}, 'stop': ['==='], 'temperature': 0.3, 'top_p': 0.7}\n",
      "----\n",
      "Finished api-req2.json -> 200 (13.864s)\n",
      "----\n",
      "{'model': 'inference-gemma-12b-it', 'max_tokens': 4000, 'messages': [{'content': [{'text': 'Your task is to describe the information in the image I provide to you COMPLETELY in a structured format, along with a narrative description of the contents. The image will be deleted so it is vital you capture all of the information. Use the templates you created earlier in the chat to rewrite every artifact in the image COMPLETELY.\\\\n\\\\nPlease provide the rewritten image data without additional commentary or introduction in plain text and NOT markdown.\\\\n\\\\nIt is important that you translate EVERYTHING in your response into English, including the keys AND values in any JSON.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': 'Analyze the below text from a document to infer what type of document it is and what the main themes, topics, and purpose of the document are. Create a concise summary of about 5-6 sentences in length, focusing solely on the important themes and points of this document.', 'type': 'text'}], 'role': 'user'}, {'content': [{'text': 'This document describes the advancements in machine learning models, particularly focusing on the comparison between proprietary commercial models and open-source alternatives. It highlights three main aspects: parameter scale, image resolution, and multilingual capabilities, illustrating the performance gaps between these two categories. The document introduces InternVL 1.5, which aims to bridge these gaps through continuous learning, enhanced resolution, and improved bilingual proficiency. The main participants involved in this discussion include developers and researchers in the field of machine learning and artificial intelligence. The document emphasizes the need for improved performance in non-English scene understanding and optical character recognition tasks.\\\\n\\\\nKeywords: machine learning, proprietary models, open-source models, InternVL 1.5, multilingual capabilities, image resolution, parameter scale, OCR, artificial intelligence, continuous learning.', 'type': 'text'}], 'role': 'assistant'}, {'content': [{'text': 'I am providing you with an image. Create detailed instructions for processing the image as if you are explaining what it contains to a blind person who cannot see it.', 'type': 'text'}], 'role': 'user'}, {'content': [{'text': '### Custom Instructions for JSON Conversion\\\\n\\\\n1. **List all components**:\\\\n   - **Shapes**: Three circles representing different percentage ranges (30% and below, 30%-50%, 50%-70%, 70%-90%).\\\\n   - **Text**: \\\\n     - Percentages (26.43%, 39.21%, 22.91%, 5.29%).\\\\n     - Labels for each percentage range in both English and Chinese.\\\\n     - Descriptive text on the left side about \\\\\"InternVL 1.5\\\\\" including features like \\\\\"Dynamic High-Resolution,\\\\\" \\\\\"Strong Foundation Models,\\\\\" and \\\\\"High-Quality Bilingual Dataset.\\\\\"\\\\n   - **Arrows**: Vertical lines connecting the percentages to their respective circles.\\\\n   - **Color**: Blue circles with varying shades indicating different values.\\\\n\\\\n2. **Describe the relationships in detail**:\\\\n   - The circles represent performance metrics of InternVL 1.5, with each circle\\'s size correlating to the percentage it represents.\\\\n   - The vertical arrows indicate a direct relationship between the percentage values and their corresponding circles, showing a flow of information from the text to the visual representation.\\\\n   - The descriptive text on the left provides context for the data represented in the circles, indicating that these percentages relate to the capabilities of the InternVL 1.5 model.\\\\n\\\\n3. **Create Summary JSON**:\\\\n   - Capture the overall structure and context of the image, including figure title and number if available. Based on the analysis, the summary JSON could look like this:\\\\n   ```json\\\\n   {\\\\n     \\\\\"figure_title\\\\\": \\\\\"Characteristics of InternVL 1.5\\\\\",\\\\n     \\\\\"figure_number\\\\\": 1,\\\\n     \\\\\"description\\\\\": \\\\\"This diagram illustrates the performance metrics of InternVL 1.5 across various percentage ranges.\\\\\",\\\\n     \\\\\"components\\\\\": [\\\\n       {\\\\\"label\\\\\": \\\\\"30% and below\\\\\", \\\\\"value\\\\\": 26.43},\\\\n       {\\\\\"label\\\\\": \\\\\"30%-50%\\\\\", \\\\\"value\\\\\": 39.21},\\\\n       {\\\\\"label\\\\\": \\\\\"50%-70%\\\\\", \\\\\"value\\\\\": 22.91},\\\\n       {\\\\\"label\\\\\": \\\\\"70%-90%\\\\\", \\\\\"value\\\\\": 5.29}\\\\n     ],\\\\n     \\\\\"relationships\\\\\": [\\\\n       {\\\\\"source\\\\\": \\\\\"30% and below\\\\\", \\\\\"target\\\\\": \\\\\"Circle 1\\\\\", \\\\\"type\\\\\": \\\\\"size\\\\\"},\\\\n       {\\\\\"source\\\\\": \\\\\"30%-50%\\\\\", \\\\\"target\\\\\": \\\\\"Circle 2\\\\\", \\\\\"type\\\\\": \\\\\"size\\\\\"},\\\\n       {\\\\\"source\\\\\": \\\\\"50%-70%\\\\\", \\\\\"target\\\\\": \\\\\"Circle 3\\\\\", \\\\\"type\\\\\": \\\\\"size\\\\\"},\\\\n       {\\\\\"source\\\\\": \\\\\"70%-90%\\\\\", \\\\\"target\\\\\": \\\\\"Circle 4\\\\\", \\\\\"type\\\\\": \\\\\"size\\\\\"}\\\\n     ]\\\\n   }\\\\n   ```\\\\n\\\\n4. **Create Detailed JSON for Elements and Relationships**:\\\\n   - Each circle can be represented in JSON format, capturing its size and relationship to the percentage:\\\\n   ```json\\\\n   {\\\\n     \\\\\"element\\\\\": \\\\\"Circle 1\\\\\",\\\\n     \\\\\"percentage\\\\\": 26.43,\\\\n     \\\\\"relationship\\\\\": {\\\\n       \\\\\"connected_to\\\\\": \\\\\"30% and below\\\\\",\\\\n       \\\\\"size\\\\\": \\\\\"small\\\\\"\\\\n     }\\\\n   }\\\\n   ```\\\\n   - Repeat for other circles, adjusting the values and relationships accordingly.\\\\n\\\\n5. **Narrate the JSON**:\\\\n   - The narrative should describe the JSON objects, explaining the relationships:\\\\n   - \\\\\"Circle 1 represents 26.43% for the range of 30% and below, indicating a smaller size. Circle 2 corresponds to 39.21% for the 30%-50% range, showing a medium size, while Circle 3 represents 22.91% for the 50%-70% range, and Circle 4 shows 5.29% for the 70%-90% range, indicating a much smaller size.\\\\\"\\\\n\\\\n6. **Final JSONL and Narrative Instructions**:\\\\n   - Group the JSON objects at the top without indentation:\\\\n   ```json\\\\n   {\\\\\"figure_title\\\\\":\\\\\"Characteristics of InternVL 1.5\\\\\",\\\\\"figure_number\\\\\":1,\\\\\"description\\\\\":\\\\\"This diagram illustrates the performance metrics of InternVL 1.5 across various percentage ranges.\\\\\",\\\\\"components\\\\\":[{\\\\\"label\\\\\":\\\\\"30% and below\\\\\",\\\\\"value\\\\\":26.43},{\\\\\"label\\\\\":\\\\\"30%-50%\\\\\",\\\\\"value\\\\\":39.21},{\\\\\"label\\\\\":\\\\\"50%-70%\\\\\",\\\\\"value\\\\\":22.91},{\\\\\"label\\\\\":\\\\\"70%-90%\\\\\",\\\\\"value\\\\\":5.29}],\\\\\"relationships\\\\\":[{\\\\\"source\\\\\":\\\\\"30% and below\\\\\",\\\\\"target\\\\\":\\\\\"Circle 1\\\\\",\\\\\"type\\\\\":\\\\\"size\\\\\"},{\\\\\"source\\\\\":\\\\\"30%-50%\\\\\",\\\\\"target\\\\\":\\\\\"Circle 2\\\\\",\\\\\"type\\\\\":\\\\\"size\\\\\"},{\\\\\"source\\\\\":\\\\\"50%-70%\\\\\",\\\\\"target\\\\\":\\\\\"Circle 3\\\\\",\\\\\"type\\\\\":\\\\\"size\\\\\"},{\\\\\"source\\\\\":\\\\\"70%-90%\\\\\",\\\\\"target\\\\\":\\\\\"Circle 4\\\\\",\\\\\"type\\\\\":\\\\\"size\\\\\"}]}\\\\n   ```\\\\n   - Below that, provide the narrative description that corresponds to the JSON content.', 'type': 'text'}], 'role': 'assistant'}, {'content': [{'text': 'Here is the text that is on the same page as the graphic. It may or may not be relevant to the graphic:\\\\n\\\\n更为 复杂 的 内容 解析\\\\nThis gap is mainly reflected in the following three as-\\\\n pects : ( 1 ) Parameter Scale : Recent proprietary commer-\\\\n cial MLLMS [ 7 , 37 , 83 , 88 ] typically scales not less than\\\\n 100 billion parameters , while open - source models com-\\\\n monly employ a 300 million parameter vision foundation\\\\n model ( VFM ) , which is integrated with either a 7 billion\\\\n or 13 billion LLMs . ( 2 ) Image Resolution : Proprietary\\\\n commercial models typically employ a dynamic resolution\\\\n approach , preserving the original aspect ratio to facilitate\\\\n detailed scene and document understanding . In contrast ,\\\\n open - source models generally train with fixed resolutions\\\\n [ 20 , 25 , 58 , 67 , 112 , 137 ] , such as 336x336 and 448 × 448 ,\\\\n leading to a considerable gap in capabilities relative to com-\\\\n mercial counterparts . ( 3 ) Multilingual Capability : Propri-\\\\n etary models often leverage extensive multilingual datasets\\\\n for training , enhancing their performance across diverse\\\\n languages . However , open - source models predominantly\\\\n utilize English data , relying on the zero - shot capabilities of\\\\n LLMs for other languages , e.g. LLaVA - NeXT [ 60 ] . This re-\\\\n sults in sub - optimal performance in non - English scene un-\\\\n derstanding and OCR tasks .\\\\n1.5\\\\n InternVL\\\\nAGI\\\\nDynamic High - Resolution\\\\n448 4K Resolution\\\\nStrong Foundation Models\\\\n InternViT - 6B - 448px - V1.5 +\\\\nInternLM2-20B\\\\nHigh - Quality Bilingual Dataset\\\\n Captioning , General QA , Science ,\\\\n Chart , Mathematics , Knowledge ,\\\\n OCR , Document , Grounding ,\\\\n Conversation , Chinese , English\\\\nCharacteristics of InternVL 1.5 . Intern VL 1.5 features\\\\n representation through continuous learning , flexible\\\\n capabilities , and robust bilingual proficiency in English\\\\n, positioning it as a competitive MLLM .\\\\n30 % 及 以下\\\\n50 % -70 % ( 70 % )\\\\n26.43 %\\\\n22.91 %\\\\n30 % -50 % ( 50 % )\\\\n70 % -90 % ( 90 % )\\\\n39.21 %\\\\n5.29 %\\\\nTo bridge the gap , we introduce InternVL 1.5 , integrat-\\\\n ing three major improvements to enhance its performance\\\\n and usability . ( 1 ) We implement a continuous learning ap-\\\\n proach to a large - scale VFM - Intern ViT - 6B [ 20 ] , refining\\\\nFigure 2.\\\\n strong visual\\\\n resolution\\\\nand Chinese\\\\n第十五 届 中国 数据库 技术 大会\\\\nDATABASE TECHNOLOGY CONFERENCE CHINA 2024\\\\n行业 OCR 的 识别 度 普遍 在 70 %\\\\nDTCC\\\\n朗丽玆 西山 花园 酒店 8 月 22-24 日\\\\nDB2\\\\nMPP\\\\nIT - 168 .\\\\nU ChinaUnix\\\\nOracie\\\\nSQL\\\\nITPUB', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/1.jpg'}, 'type': 'image_url'}, {'text': 'Using the template or guidelines we discussed, please rewrite the given image into JSONL format, along with a narrative description. Your focus should be on rewriting the contents of the image according to the instructions you created earlier.\\\\n\\\\nIt is important that you translate EVERYTHING in your response into English, including the keys AND values in any JSON.\\\\n\\\\nBe careful with the numbers, double check your math. Focus on describing the information rather than the visual appearance. Unless the visual appearance conveys information to the reader.\\\\n\\\\nIt is CRITICAL that you include EVERY SECTION OF THE IMAGE!!\\\\n\\\\nIt is also absolutely VITAL that you create the summary JSONL object first as described in your instructions, while preserving any important titles and figure numbers.\\\\n\\\\nIf the image contains a chart of some kind, you must represent every datapoint as JSONL objects.\\\\n\\\\nRemember, the instructions describe how to create a summary JSONL then section JSONL for each section of the graphic.\\\\n\\\\nRemember, you must provide both a JSONL representation along with a narrative description of each JSON object. Follow the instructions you created earlier for both.\\\\nReturn only the JSONL object along with the narrative description. Do not reference the \\\\\"JSON object\\\\\" or \\\\\"narrative description\\\\\". Only return the actual object and description.\\\\nPlease return your response in plain text and NOT markdown. The JSONL should not contain indentation, formatting, or new lines except between JSON objects.\\\\n\\\\nIt is important that you translate EVERYTHING in your response into English, including the keys AND values in any JSON.\\\\n\\\\nHere\\'s the image again:', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/figure-1-0.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'response_format': {'type': 'text'}, 'stop': ['==='], 'temperature': 0.3, 'top_p': 0.7}\n",
      "----\n",
      "Finished 5.json -> 200 (16.556s)\n",
      "----\n",
      "{'max_tokens': 4000, 'messages': [{'content': [{'text': 'Your task is to analyze the provided image and generate **custom instructions** for converting its visual information into JSON and narrative text. Focus on identifying **all elements** in the image and, most importantly, the **relationships and insights** between those elements. Use any surrounding text on the page to provide additional context or clarity about the diagram\\'s purpose, themes, or connections. It is critical that your instructions capture these relationships and that they are properly reflected in the JSON and narrative descriptions. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **Analyze the Image**: Identify **all visible components** of the image. These could include text, numbers, shapes, icons, lines, arrows, colors, groupings, etc. Be thorough in listing all the individual elements, focusing on **relevant relationships and insights** between them. This is the most important part. Relationships could include:\\\\n  - Elements linked by lines or arrows (e.g., showing flow, sequence, or connection).\\\\n  - Groupings by location on axes or timelines, proximity, color, or other visual cues (e.g., items that belong to the same category, family, or set).\\\\n  - Comparisons between elements (e.g., sizes, positions, directions).\\\\n  - Directionality or sequence indicated by arrows, lines, or ordering.\\\\n  - Any other **interactions** that tie elements together, such as overlapping shapes, aligned elements, or color-coded regions.\\\\n  - Higher-level patterns or themes visible in the diagram, especially if clarified by surrounding text.\\\\n\\\\n2. **Describe Relationships in JSON**: For each relationship identified in the image, explain how to capture it in JSON. This might include:\\\\n  - Indicating a **direction** or **flow** between two elements connected by an arrow (e.g., `\\\\\"direction\\\\\":\\\\\"Element A flows to Element B\\\\\"`) if it conveys process or sequence.\\\\n  - **Grouping** elements that share a color, alignment, or proximity (e.g., `\\\\\"group\\\\\":\\\\\"green elements\\\\\",\\\\\"aligned_with\\\\\":\\\\\"central box\\\\\"`) to represent categories or clusters.\\\\n  - Expressing **comparative relationships** (e.g., `\\\\\"Element A is larger than Element B\\\\\"` or `\\\\\"Element A is above Element B\\\\\"`).\\\\n  - Assigning values from an axis or legend.\\\\n  - Capturing any patterns or trends, such as changes across a timeline, using surrounding text for additional insights.\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example that you should customize to fit the image, if relationships must be described:\\\\n```\\\\n{\\\\\"element\\\\\":\\\\\"A\\\\\",\\\\\"relationship\\\\\":{\\\\\"connected_to\\\\\":\\\\\"B\\\\\",\\\\\"direction\\\\\":\\\\\"left to right\\\\\"}}\\\\n```\\\\n\\\\n3. **Create a Summary JSON Object**: After analyzing the elements and relationships, create a summary JSON object that captures the **overall structure, context, and purpose** of the image, including the relationships you identified and any themes drawn from surrounding text.\\\\n  - Use specific examples from the image to show how to construct the summary, but avoid placeholders or general terms.\\\\n  - If the figure has a title or a number or both, such as table 1 or figure 2, it is ABSOLUTELY CRITICAL that you create instructions to capture these titles and numbers within the summary JSON object. In addition to preserving the title, create a key and value for the figure or table numbers like `{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\": 1}` in **Korean**\\\\n    - The figure title or number may not be included in the image but may be found in the surrounding text.\\\\n    - Do not include the figure title and number if they cannot be found.\\\\n    - Use the nomenclature in the image. If the figure is called \\\\\"table\\\\\" call it \\\\\"table_title\\\\\" and  \\\\\"table_number\\\\\". etc...\\\\n  - If the image is a chart or graph, include a summary of the **overall trend** or **purpose** represented by the chart or graph in the summary JSON object!!!\\\\n  - **Only add fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", or \\\\\"relationships\\\\\" if they offer key insights** about the image.\\\\n  - Example. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"figure_title\\\\\":\\\\\"Diagram of System Flow\\\\\",\\\\\"figure_number\\\\\":4,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"components\\\\\":[\\\\\"Z\\\\\"],\\\\\"trends\\\\\":[\\\\\"Q\\\\\"],\\\\\"relationships\\\\\":[{\\\\\"source\\\\\":\\\\\"Process A\\\\\",\\\\\"target\\\\\":\\\\\"Process B\\\\\",\\\\\"type\\\\\":\\\\\"flow\\\\\"},{\\\\\"group\\\\\":\\\\\"blue items\\\\\",\\\\\"elements\\\\\":[\\\\\"Box 1\\\\\",\\\\\"Box 2\\\\\"]}]}\\\\n```\\\\n\\\\n4. **Detailed JSON for Elements and Relationships**: For each individual component, provide detailed instructions on how to represent it as a JSON object.\\\\n  - Focus on **preserving relationships** between elements. Make sure that any lines, arrows, groupings, or comparisons are reflected in the JSON as attributes.\\\\n  - Ensure each JSON object includes attributes describing its relationships to other elements, such as:\\\\n    - `\\\\\"connected_to\\\\\":\\\\\"Element B\\\\\"`\\\\n    - `\\\\\"group\\\\\":\\\\\"blue items\\\\\"`\\\\n    - `\\\\\"relative_position\\\\\":\\\\\"above Element C\\\\\"`\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - If the figure is a graph, bar chart or some other type of chart, create instructions to capture EVERY SINGLE data point in the chart.\\\\n    - It is ABSOLUTELY VITAL you **create instructions to capture every datapoint in the chart** COMPLETELY.\\\\n  - Include the relative changes between the data points in JSON as key-values.\\\\n  - Example:\\\\n```\\\\n{\\\\\"element\\\\\":\\\\\"Process A\\\\\",\\\\\"connected_to\\\\\":\\\\\"Process B\\\\\",\\\\\"direction\\\\\":\\\\\"flows to\\\\\"}\\\\n```\\\\n\\\\n5. **Narrative Instructions**: Provide guidance on how to convert the JSON into a narrative description. The narrative should describe the **relationships** between elements, clearly explaining how they connect or interact.\\\\n  - For example, \\\\\"Process A is connected to Process B, with an arrow showing a flow from left to right.\\\\\"\\\\n  - Avoid using placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"; base the narrative on the actual elements and relationships in the image.\\\\n\\\\n6. **Final Organization**: Once the individual JSON objects are described, instruct that the JSONL should be grouped at the top without indentation or extra formatting. The narrative description should be grouped at the bottom, representing the JSON content in sentence form. Ensure the narrative corresponds directly to the JSON and provides a full description of the image.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in Korean**: Ensure that all JSON keys, values, and narrative text are written in Korean, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n- **Use surrounding text for context**: Refer to additional text to help identify themes, relationships, or trends, as well as the title or figure number if they are not within the image itself.\\\\n- **Only add fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", and \\\\\"relationships\\\\\"** if they offer meaningful insights about the image. Translate all keys, values, and text into Korean.\\\\n- **Figure/graph/chart title and number**: Create instructions to capture BOTH the figure title and number, if they exist, in the image. If they are not in the image, they may be found in the surrounding text. The entire figure title must be captured in **Korean** like this `{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\":1}`, except translate \\\\\"figure title\\\\\" and \\\\\"figure number\\\\\" into Korean, as well as in the narrative text.\\\\n- Translate all keys, values, and text into Korean.\\\\n\\\\nThe goal is to ensure that the structure, relationships, and content of the image are fully captured in both JSON and the narrative, with insights enhanced by the surrounding text.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': \"Here is the text that is on the same page as the graphic. It may or may not be relevant to the graphic:\\\\n\\\\n국제 금융 센터\\\\nIssue Analysis\\\\n[ 위험 요인 ] 고금리 장기화 중동 불안 잠재 달러 강세 심화 가능성 상업용 부동산\\\\n 위험 등 이 복합 작용 한다면 경기 회복 기대감 및 투자 심리 가 추가적으로 악화 할 가능성\\\\n ● 고금리 장기화 디스인플레이션 지연 으로 美 연준 의 금리 인하 기대감 이 약해지고 , 금리 인하\\\\n 시기 를 가늠 중인 중앙 은행 들 도 美 연준 과 통화 정책 격차 의 부작용 을 고려 하면서 주요국\\\\n 전반 에서 고금리 기조 장기화 , 수요 · 투자 위축 , 신용 악화 등 부작용 우려\\\\nㅇ ( 현황 ) 최근 미국 등 주요국 의 물가 가 반등 하면서 디스인플레이션 경로 가 예상 보다\\\\n 험난한 경로 ( bumpy road to disinflation ) 로 진행\\\\n-\\\\n-\\\\n미국 소비자 물가 상승률 ( 전월비 ) 이 금년 1 분기 중 0.3 ~ 0.4 % 를 기록 하여 전년 4 분기\\\\n0.1 ~ 0.2 % 에 비해 크게 높아진 데다 전년 동월비 기준 으로 도 3 개월 째 반등 \\\\u003c 표 1 \\\\u003e\\\\n유로존 소비자 물가 상승률 ( 전월비 ) 이 금년 2,3 월 에 각각 0.6 % , 0.8 % 로 크게 높아진 가운데 특히\\\\n 서비스 물가 가 전년 동월비 기준 으로 4 % 를 자 속상 하며 여전히 인플레이션 목표치 와 거리\\\\nㅇ ( 평가 ) 디스인플레이션 후퇴 로 주요 중앙 은행 들이 단기간 내 강하게 금리 인하 를\\\\n 시행 하는 것에 대한 부담 이 커짐 에 따라 경기 회복 추세 에도 부정적인 영향\\\\n\\\\t|\\\\t\\\\u003c 표 1 \\\\u003e OIS 에 반영된 미국 · 유로존 영국 의 금년 말 기준 금리 수준 전망치 변화\\\\n구분\\\\t|\\\\t현 기준 금리 수준 '24 년 1 월말 '24 년 2 월말 '24 년 3 월말 24 년 4 월말\\\\n\\\\t|\\\\t4.02 4.65 4.80 5.16\\\\n미국 ( Fed )\\\\t|\\\\t5.50\\\\n\\\\t|\\\\t( 5.9 ) ( 3.4 ) ( 2.8 ) ( 1.4 )\\\\n\\\\t|\\\\t2.90 3.59 3.61 3.78\\\\n유로존 ( ECB )\\\\t|\\\\t4.50\\\\n\\\\t|\\\\t( 6.4 ) ( 3.6 ) ( 3.6 ) ( 2.9 )\\\\n\\\\t|\\\\t4.12 4.62 4.52 4.81\\\\n영국 ( BOE )\\\\t|\\\\t5.25\\\\n\\\\t|\\\\t( 4.5 ) ( 2.5 ) ( 2.9 ) ( 1.8 )\\\\n주 :( ) 안은 baby step ( -0.25 % p ) 기준 금리 인하 횟수\\\\n자료 : Bloomberg\\\\n・ 연준 의 HAL ( Higher for Longer ) 로 ECB 를 포함한 여타 중앙 은행 들의 금리 인하 폭 이\\\\n 줄어들고 시기 도 이연 될 가능성\\\\nㅇ ( 영향 ) 고금리 기조 장기화 시 경제 주체 들의 수요 · 투자 위축 , 신용 악화 우려 , 금리\\\\n 하향 을 기대 했던 투자 자금 이탈 과 자산 가격 조정 등 경제 · 금융 부작용 이 지속될 소지\\\\n\\\\u003c 그림 3 \\\\u003e 연말 까지 정책 금리 인하 폭 확률 추이\\\\n\\\\t|\\\\t\\\\u003c 표 2 \\\\u003e 주요국 소비자 물가 증감율 추이\\\\n구분\\\\t|\\\\t'23 .10 '23 .11 23.12 24.1 월 24.2 월 '24 .3\\\\n미국 CPI MoM\\\\t|\\\\t0.1 0.2 0.2 0.3 0.4 0.4\\\\n미국 CPI YoY\\\\t|\\\\t3.2 3.1 3.4 3.1 3.2 3.5\\\\n미국 근원 PCE MoM\\\\t|\\\\t0.1 0.1 0.2 0.5 0.3\\\\n유로존 CPI MOM\\\\t|\\\\t0.1 -0.6 0.2 -0.4 0.6 0.8\\\\n유로존 CPI YoY\\\\t|\\\\t2.9 2.4 2.9 2.8 2.6 2.4\\\\n영국 CPI MoM\\\\t|\\\\t0.0 -0.2 0.4 -0.6 0.6 0.6\\\\n영국 CPI YoY\\\\t|\\\\t4.6 3.9 4.0 4.0 3.4 3.2\\\\n50\\\\n100bp 인하\\\\n-50bp 인하\\\\n• 75bp 인하\\\\n-25bp 인하\\\\n동결\\\\n40\\\\n30\\\\n20\\\\n10\\\\n0\\\\n03.01\\\\n03.16\\\\n03.31\\\\n04.15\\\\n자료 : Bloomberg\\\\n자료 : CME FedWatch\\\\nKCIF\", 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/3.jpg'}, 'type': 'image_url'}, {'text': 'Here is an image of a diagram or graphic. Your task is to analyze the image and provide **custom** instructions on how to convert the visual information into JSON and narrative text. **Do not paraphrase this task**. Instead, analyze the **specific relationships** within the image and create instructions based on the elements and how they are connected. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **List all components**: First, list all visible components in the image, such as text, numbers, arrows, lines, icons, shapes, and color coding.\\\\n  - Use any surrounding text to help clarify the purpose of each component, and explain what each component represents, with emphasis on how elements relate to each other:\\\\n  - Focus especially on **relationships** between elements, like directional arrows (e.g., flow or process sequence), placement on axes, groupings by color or proximity, and size or order comparisons. Be sure to describe each element\\'s purpose, integrating any context provided by the text.\\\\n\\\\n2. **Describe the relationship in details**: For each relationship, explain what is being conveyed and the purpose of the connection (e.g., causal flow, comparison, importance). This might include directional arrows (e.g., showing flow or sequence), visual groupings (e.g., by color or alignment), or comparative relationships (e.g., sizes, positions, or importance).\\\\n  - Avoid listing elements without context—explain each relationship in detail if it adds clarity, and refer to surrounding text if it provides insight.\\\\n  - Be specific in describing how the relationships should be represented in JSON, rather than focusing solely on individual elements.\\\\n  - For diagrams, clarify what each connection represents and the intent behind the structure.\\\\n  - For graphs, highlight patterns, trends, or notable changes (e.g., upward/downward trends, fluctuations). Summarize these trends in your instructions to be captured in JSON.\\\\n\\\\n3. **Create Summary JSON**: After identifying the components, provide instructions for creating a **summary JSON object** that captures the overall structure, meaning, and context of the image. This should include any **figure titles**, **numbers**, headers, and main topics or themes in the image. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis. For example, for graphs, you could add a \\\\\"trends\\\\\" field. For a flow diagram, something like \\\\\"components\\\\\" attribute might make sense. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the image, especially for identifying the figure title and number if they are not within the image itself.\\\\n  - If a title or figure number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative.\\\\n    - Do not include the figure title and number if they cannot be found.\\\\n    - Use the nomenclature in the image. If the figure is called \\\\\"table\\\\\" call it \\\\\"table_title\\\\\" and  \\\\\"table_number\\\\\". etc...\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information and insights* being conveyed in the image. Use real values from the image and not default values. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\":1,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"components\\\\\":[\\\\\"Z\\\\\"],\\\\\"trends\\\\\":[\\\\\"Q\\\\\"],\\\\\"relationships\\\\\":[{\\\\\"source\\\\\":\\\\\"Process A\\\\\",\\\\\"target\\\\\":\\\\\"Process B\\\\\",\\\\\"type\\\\\":\\\\\"flow\\\\\"},{\\\\\"group\\\\\":\\\\\"blue items\\\\\",\\\\\"elements\\\\\":[\\\\\"Box 1\\\\\",\\\\\"Box 2\\\\\"]}]}\\\\n```\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n4. **Create Detailed JSON for Elements and Relationships:**: Explain how to convert each individual component into JSON that reflects its relationships with other elements, if there are relationships between elements (e.g., arrows showing direction, data points on a graph).\\\\n  - The JSON should capture connections, groupings, directionality, trends or changes observed, and other relationships between the elements, not just the elements themselves.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - For charts or data visualizations, capture every individual data point, including relative changes, and summarize the overall trend in the summary JSON object, using additional text to help explain overall patterns if relevant.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n5. **Narrate the JSON**: Provide instructions on how to convert the JSON into full sentences. The narrative should describe each JSON object in Korean, detailing the relationships and meaning of each part of the image. Avoid using placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"—base the narrative on the actual content of the image.\\\\n\\\\n6. **Final JSONL and Narrative Instructions**: Instruct that the JSON objects should be grouped at the top in a JSONL format (without indentation or extra formatting). Below that, provide the narrative sentences that describe the JSON content fully.\\\\n\\\\n**Important Notes**:\\\\n- It is critical that your response is customized to the **relationships** and **insights** conveyed in the image, and not a paraphrase of these instructions.\\\\n- Use the surrounding text to capture additional context, high-level insights, or to capture the figure title and number if they are not visible within the image.\\\\n- If a title or figure number exists, make sure you capture this information in the summary JSON object and reflect it in the narrative. The figure number and title may not be in the image but may be found in the surrounding text.\\\\n- Only include fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", and \\\\\"relationships\\\\\" in the summary JSON if they convey **key insights**.\\\\n- Make sure all relationships are captured, whether through arrows, lines, proximity, color coding, or other visual cues.\\\\n- Avoid placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"; use actual elements from the image and describe their relationships in detail.\\\\n- Translate all keys, values, and text into Korean.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/figure-3-0.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'inference-gemma-12b-it', 'response_format': {'type': 'text'}, 'stop': ['==='], 'temperature': 0.3, 'top_p': 0.7}\n",
      "----\n",
      "Finished api-req1.json -> 200 (19.398s)\n",
      "----\n",
      "{'max_tokens': 4000, 'messages': [{'content': [{'text': 'You are a helpful assistant specialized in creating instructions for analyzing and transforming table images into JSON and narrative text. Your task is to analyze the provided image of a table and generate custom instructions that explain how to structure the content of the table into JSON and narrative text. Your output should include **only instructions**. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\nThe most important part of your task is to ensure that every single **relationship** between the cells, headers, and overall structure is **captured accurately**. It is not enough to convert the table cells into JSON individually; the **relationships between the data** (such as row and column headers, data groupings, and interactions) must be reflected in the final JSON.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n1. **Analyze the Table Structure**: **Identify and list all visible components** of the table. These could include the table title, table number, column headers, row headers, data cells, or any other visual elements.\\\\n  - Focus on identifying the **relationships** between headers and data cells. For example:\\\\n    - If the table has column and row headers, describe how the headers relate to the values in each cell.\\\\n    - If cells are grouped or have shared characteristics (e.g., by row or column), describe how these groups should be represented in JSON.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n\\\\n2. **Summary JSON Instructions**: Create detailed instructions for constructing a **summary JSON object** that captures high-level information, such as the table title, number, and main topics or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis, if they highlight key insights (e.g., trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - Include the **table title and number** if they exist in the image or surrounding text. It is critical that the title and number be accurately represented in the summary JSON object.\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. It  *must be customized* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n  - If the table lacks a title or number, make it clear in the instructions that the JSON should reflect that it is missing.\\\\n\\\\n3. **Detailed JSON for Table Cells**: For each data cell in the table, provide instructions on how to create a **single JSON object** that reflects both the data in the cell and the **relationship** between that data and its headers.\\\\n  - If the table is organized in rows, describe how to capture the relationships between the **row header** and each corresponding cell in that row. For example:\\\\n```\\\\n{\\\\\"header_1\\\\\":\\\\\"Value_1\\\\\",\\\\\"header_2\\\\\":\\\\\"Value_2\\\\\"}\\\\n```\\\\n  - If the table is organized in columns, describe how to capture the relationships between the **column header** and each cell in that column.\\\\n  - **Ensure that every cell has both a key (based on headers) and a value (based on the cell\\'s content)**, and the relationships between headers and values are reflected clearly.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n4. **Table Narrative Instructions**: Provide instructions for narrating the contents of the JSON into **complete sentences** that describe the relationships between the cells.\\\\n  - The narrative must clearly explain the **contents** of the table and the **relationships** between headers and data in simple language.\\\\n  - Do not use technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format\\\\\"; simply describe the table data in sentence form.\\\\n  - **Example of a narrative**:\\\\n    - \\\\\"In this table, the category is \\'Food,\\' the amount is \\'100,\\' and the date is \\'01-01-2024.\\' Another entry in the table shows that the category is \\'Transport,\\' the amount is \\'50,\\' and the date is \\'01-02-2024.\\'\\\\\"\\\\n\\\\n5. **Final Organization**: After describing each table cell\\'s content, instruct that the JSON objects should be grouped at the top into a **JSONL format** without indentation or extra formatting.\\\\n  - The narrative description should be grouped at the bottom, explaining the JSON content in full sentences.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in Korean**: Ensure that all JSON keys, values, and narrative text are written in Korean, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': 'Here is an image of a table. Your task is to analyze the image and provide **custom instructions** on how to convert the table into JSON and narrative text, ensuring that both the **content** and the **relationships** between the elements in the table are captured accurately. Do not generate actual JSON or narrative text. Your response should be customized instructions that can be used to prompt an LLM to process the image content into JSON and narrative text accurately and reliably. Focus on providing comprehensive and customizable guidance that can be used in subsequent tasks.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\n- **Identify and list all components**: Identify the table title, table number, column headers, row headers, data cells, and layout of information.\\\\n  - Use any surrounding text to help clarify the structure and purpose of the table.\\\\n  - Focus on the relationships between the headers and the data in each cell. For example, how does each column header relate to the values in that column? How do row headers correspond to the data in the rows?\\\\n  - Identify how the table lays out information: in columns, rows, or some combination.\\\\n\\\\n- **Create Summary JSON**: After analyzing the table, provide instructions for creating a **summary JSON object** that captures high-level information, such as the table title, number, and main headers. This should also include a description of the table\\'s purpose, main topics, or themes. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image, based on your analysis, only if they convey key insights (e.g., recurring patterns or trends across rows or columns). For example, you could add a \\\\\"trends\\\\\" field for any patterns or trends in the table. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the table.\\\\n  - If a table title or table number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative\\\\n    - Do not include the table title and number if they cannot be found.\\\\n    - Use the nomenclature in the table. If the table is called \\\\\"figure\\\\\" call it \\\\\"figure_title\\\\\" and  \\\\\"figure_number\\\\\". etc...\\\\n  - Translate all keys, values, and text into Korean.\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information* being conveyed in the summary object. Translate all keys, values, and text into Korean.\\\\n```\\\\n{\\\\\"table_title\\\\\":\\\\\"Example Table\\\\\",\\\\\"table_number\\\\\":5,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"trends\\\\\":\\\\\"Q\\\\\"}\\\\n```\\\\n\\\\n- **Create Detailed JSON for Table Cells**: Provide instructions on how to convert each cell into a **single JSON object** that reflects both the **data in the cell** and the **relationship between the headers and data**.\\\\n  - For row-based tables, explain how to capture the relationships between row headers and each cell.\\\\n  - For column-based tables, explain how to capture the relationships between column headers and each cell.\\\\n  - It is **vital** that every cell has both a **key** (based on headers) and a **value** (based on cell content).\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - Translate all keys, values, and text into Korean.\\\\n\\\\n- **Narrate the JSON**: Provide instructions for how to narrate each JSON object into a complete sentence, explaining the relationships between the table\\'s headers and data in simple language.\\\\n  - Ensure that the narrative text is written without referring to technical terms like \\\\\"JSON object\\\\\" or \\\\\"narrative format.\\\\\"\\\\n\\\\n- **Final JSONL and Narrative Instructions**: Group the JSON objects together at the top in a JSONL format (without indentation).\\\\n  - The narrative text should be grouped at the bottom and should describe the contents of the table in full sentences.\\\\n\\\\n**Important Notes**:\\\\n\\\\n- It is crucial that your instructions focus on capturing **relationships between table headers and data cells** rather than just converting cells individually.\\\\n- Use the surrounding text to capture additional context and high-level insights.\\\\n- Make sure that both the JSON and the narrative descriptions reflect the **relationships** between the elements, such as how headers correspond to cell values.\\\\n- It is absolutely vital that you create instructions to capture BOTH the table title and number, if they exist in the image or surrounding text, in the summary JSON object. The entire table title must be captured IN THE LANGUAGE OF THE CONTENT like this `{\\\\\"table title\\\\\":\\\\\"TITLE\\\\\",\\\\\"table number\\\\\":1}`, except translate \\\\\"table title\\\\\" and \\\\\"table number\\\\\" into the language of the content.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **Korean**. Translate everything into Korean.\\\\n\\\\nPlease make it clear that the JSONL should not contain indentation, formatting, or new lines. \\\\nPlease provide the LLM prompt without additional commentary or notes.\\\\nRemember, it is ABSOLUTELY CRITICAL you capture ALL of the original information conveyed in the table.\\\\n\\\\nHere is the image of what I think is a table. It may or may not include column and row headers.', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/984de5a7-3db6-409d-b35a-199240d2442e/419d0b7a-b1c1-45e8-bbc3-a14e8263d0a0/table-3-0.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'model': 'inference-gemma-12b-it', 'response_format': {'type': 'text'}}\n",
      "----\n",
      "Finished simple_request.json -> 200 (28.103s)\n",
      "----\n",
      "{'model': 'inference-gemma-12b-it', 'max_tokens': 4000, 'messages': [{'content': [{'text': 'Your task is to analyze the provided image and generate **custom instructions** for converting its visual information into a structured JSON format. Focus on identifying **all elements** in the image and, most importantly, the **relationships and insights** between those elements. Use any surrounding text on the page to provide additional context or clarity about the diagram\\'s purpose, themes, or connections. It is critical that your instructions capture these relationships and that they are properly reflected in the JSON. Your response should be customized instructions that can be used to prompt an LLM to process the image content into a JSON format accurately and reliably.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\\\n\\\\n1. **Analyze the Image**: Identify **all visible components** of the image. These could include text, numbers, shapes, icons, lines, arrows, colors, groupings, etc. Be thorough in listing all the individual elements, focusing on **relevant relationships and insights** between them. This is the most important part. Relationships could include:\\\\n  - Elements linked by lines or arrows (e.g., showing flow, sequence, or connection).\\\\n  - Groupings by location on axes or timelines, proximity, color, or other visual cues (e.g., items that belong to the same category, family, or set).\\\\n  - Comparisons between elements (e.g., sizes, positions, directions).\\\\n  - Directionality or sequence indicated by arrows, lines, or ordering.\\\\n  - Any other **interactions** that tie elements together, such as overlapping shapes, aligned elements, or color-coded regions.\\\\n  - Higher-level patterns or themes visible in the diagram, especially if clarified by surrounding text.\\\\n\\\\n2. **Describe Relationships in JSON**: For each relationship identified in the image, explain how to capture it in JSON. This might include:\\\\n  - Indicating a **direction** or **flow** between two elements connected by an arrow (e.g., `\\\\\"direction\\\\\":\\\\\"Element A flows to Element B\\\\\"`) if it conveys process or sequence.\\\\n  - **Grouping** elements that share a color, alignment, or proximity (e.g., `\\\\\"group\\\\\":\\\\\"green elements\\\\\",\\\\\"aligned_with\\\\\":\\\\\"central box\\\\\"`) to represent categories or clusters.\\\\n  - Expressing **comparative relationships** (e.g., `\\\\\"Element A is larger than Element B\\\\\"` or `\\\\\"Element A is above Element B\\\\\"`).\\\\n  - Assigning values from an axis or legend.\\\\n  - Capturing any patterns or trends, such as changes across a timeline, using surrounding text for additional insights.\\\\n  - Translate all keys, values, and text into English.\\\\n  - Here is an example that you should customize to fit the image, if relationships must be described:\\\\n```\\\\n{\\\\\"element\\\\\":\\\\\"A\\\\\",\\\\\"relationship\\\\\":{\\\\\"connected_to\\\\\":\\\\\"B\\\\\",\\\\\"direction\\\\\":\\\\\"left to right\\\\\"}}\\\\n```\\\\n\\\\n3. **Create a Summary JSON Object**: After analyzing the elements and relationships, create a summary JSON object that captures the **overall structure, context, and purpose** of the image, including the relationships you identified and any themes drawn from surrounding text.\\\\n  - Use specific examples from the image to show how to construct the summary, but avoid placeholders or general terms.\\\\n  - If the figure has a title or a number or both, such as table 1 or figure 2, it is ABSOLUTELY CRITICAL that you create instructions to capture these titles and numbers within the summary JSON object. In addition to preserving the title, create a key and value for the figure or table numbers like `{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\": 1}` in **English**\\\\n    - The figure title or number may not be included in the image but may be found in the surrounding text.\\\\n    - Do not include the figure title and number if they cannot be found.\\\\n    - Use the nomenclature in the image. If the figure is called \\\\\"table\\\\\" call it \\\\\"table_title\\\\\" and  \\\\\"table_number\\\\\". etc...\\\\n  - If the image is a chart or graph, include a summary of the **overall trend** or **purpose** represented by the chart or graph in the summary JSON object!!!\\\\n  - **Only add fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", or \\\\\"relationships\\\\\" if they offer key insights** about the image.\\\\n  - Example:\\\\n```\\\\n{\\\\\"figure_title\\\\\":\\\\\"Diagram of System Flow\\\\\",\\\\\"figure_number\\\\\":4,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"components\\\\\":[\\\\\"Z\\\\\"],\\\\\"trends\\\\\":[\\\\\"Q\\\\\"],\\\\\"relationships\\\\\":[{\\\\\"source\\\\\":\\\\\"Process A\\\\\",\\\\\"target\\\\\":\\\\\"Process B\\\\\",\\\\\"type\\\\\":\\\\\"flow\\\\\"},{\\\\\"group\\\\\":\\\\\"blue items\\\\\",\\\\\"elements\\\\\":[\\\\\"Box 1\\\\\",\\\\\"Box 2\\\\\"]}]}\\\\n```\\\\n\\\\n4. **Detailed JSON for Elements and Relationships**: For each individual component, provide detailed instructions on how to represent it as a JSON object.\\\\n  - Focus on **preserving relationships** between elements. Make sure that any lines, arrows, groupings, or comparisons are reflected in the JSON as attributes.\\\\n  - Ensure each JSON object includes attributes describing its relationships to other elements, such as:\\\\n    - `\\\\\"connected_to\\\\\":\\\\\"Element B\\\\\"`\\\\n    - `\\\\\"group\\\\\":\\\\\"blue items\\\\\"`\\\\n    - `\\\\\"relative_position\\\\\":\\\\\"above Element C\\\\\"`\\\\n  - Translate all keys, values, and text into English.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - If the figure is a graph, bar chart or some other type of chart, create instructions to capture EVERY SINGLE data point in the chart.\\\\n    - It is ABSOLUTELY VITAL you **create instructions to capture every datapoint in the chart** COMPLETELY.\\\\n  - Include the relative changes between the data points in JSON as key-values.\\\\n  - Example:\\\\n```\\\\n{\\\\\"element\\\\\":\\\\\"Process A\\\\\",\\\\\"connected_to\\\\\":\\\\\"Process B\\\\\",\\\\\"direction\\\\\":\\\\\"flows to\\\\\"}\\\\n```\\\\n\\\\n5. **Narrative Instructions**: Provide guidance on how to convert the JSON into a narrative description. The narrative should describe the **relationships** between elements, clearly explaining how they connect or interact.\\\\n  - For example, \\\\\"Process A is connected to Process B, with an arrow showing a flow from left to right.\\\\\"\\\\n  - Avoid using placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"; base the narrative on the actual elements and relationships in the image.\\\\n\\\\n6. **Final Organization**: Once the individual JSON objects are described, instruct that the JSONL should be grouped at the top without indentation or extra formatting. The narrative description should be grouped at the bottom, representing the JSON content in sentence form. Ensure the narrative corresponds directly to the JSON and provides a full description of the image.\\\\n\\\\n**Key points to remember**:\\\\n\\\\n- **Everything must be in English**: Ensure that all JSON keys, values, and narrative text are written in English, including translations of any labels in the image in other languages.\\\\n- **No paraphrasing**: The response must be based entirely on the elements visible in the image. Do not paraphrase or repeat the task instructions. Customize the response based on the specific content of the image.\\\\n- **No generic placeholders**: Use actual text and data from the image wherever possible. If no clear labels exist, create meaningful keys but avoid placeholders unless absolutely necessary.\\\\n- **Use surrounding text for context**: Refer to additional text to help identify themes, relationships, or trends, as well as the title or figure number if they are not within the image itself.\\\\n- **Only add fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", and \\\\\"relationships\\\\\"** if they offer meaningful insights about the image. Translate all keys, values, and text into English.\\\\n- **Figure/graph/chart title and number**: Create instructions to capture BOTH the figure title and number, if they exist, in the image. If they are not in the image, they may be found in the surrounding text. The entire figure title must be captured in **English** like this `{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\":1}`, except translate \\\\\"figure title\\\\\" and \\\\\"figure number\\\\\" into English, as well as in the narrative text.\\\\n- Translate all keys, values, and text into English.\\\\n\\\\nThe goal is to ensure that the structure, relationships, and content of the image are fully captured in both JSON and the narrative, with insights enhanced by the surrounding text.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\\\n\\\\nIt is also critical you not format the JSON objects with indentation or new lines between attributes. Only between the JSON objects themselves.', 'type': 'text'}], 'role': 'system'}, {'content': [{'text': 'Analyze the below text from a document to infer what type of document it is and what the main themes, topics, and purpose of the document are. Create a concise summary of about 5-6 sentences in length, focusing solely on the important themes and points of this document.', 'type': 'text'}], 'role': 'user'}, {'content': [{'text': 'This document describes the advancements in machine learning models, particularly focusing on the comparison between proprietary commercial models and open-source alternatives. It highlights three main aspects: parameter scale, image resolution, and multilingual capabilities, illustrating the performance gaps between these two categories. The document introduces InternVL 1.5, which aims to bridge these gaps through continuous learning, enhanced resolution, and improved bilingual proficiency. The main participants involved in this discussion include developers and researchers in the field of machine learning and artificial intelligence. The document emphasizes the need for improved performance in non-English scene understanding and optical character recognition tasks.\\\\n\\\\nKeywords: machine learning, proprietary models, open-source models, InternVL 1.5, multilingual capabilities, image resolution, parameter scale, OCR, artificial intelligence, continuous learning.', 'type': 'text'}], 'role': 'assistant'}, {'content': [{'text': 'Here is the text that is on the same page as the graphic. It may or may not be relevant to the graphic:\\\\n\\\\n更为 复杂 的 内容 解析\\\\nThis gap is mainly reflected in the following three as-\\\\n pects : ( 1 ) Parameter Scale : Recent proprietary commer-\\\\n cial MLLMS [ 7 , 37 , 83 , 88 ] typically scales not less than\\\\n 100 billion parameters , while open - source models com-\\\\n monly employ a 300 million parameter vision foundation\\\\n model ( VFM ) , which is integrated with either a 7 billion\\\\n or 13 billion LLMs . ( 2 ) Image Resolution : Proprietary\\\\n commercial models typically employ a dynamic resolution\\\\n approach , preserving the original aspect ratio to facilitate\\\\n detailed scene and document understanding . In contrast ,\\\\n open - source models generally train with fixed resolutions\\\\n [ 20 , 25 , 58 , 67 , 112 , 137 ] , such as 336x336 and 448 × 448 ,\\\\n leading to a considerable gap in capabilities relative to com-\\\\n mercial counterparts . ( 3 ) Multilingual Capability : Propri-\\\\n etary models often leverage extensive multilingual datasets\\\\n for training , enhancing their performance across diverse\\\\n languages . However , open - source models predominantly\\\\n utilize English data , relying on the zero - shot capabilities of\\\\n LLMs for other languages , e.g. LLaVA - NeXT [ 60 ] . This re-\\\\n sults in sub - optimal performance in non - English scene un-\\\\n derstanding and OCR tasks .\\\\n1.5\\\\n InternVL\\\\nAGI\\\\nDynamic High - Resolution\\\\n448 4K Resolution\\\\nStrong Foundation Models\\\\n InternViT - 6B - 448px - V1.5 +\\\\nInternLM2-20B\\\\nHigh - Quality Bilingual Dataset\\\\n Captioning , General QA , Science ,\\\\n Chart , Mathematics , Knowledge ,\\\\n OCR , Document , Grounding ,\\\\n Conversation , Chinese , English\\\\nCharacteristics of InternVL 1.5 . Intern VL 1.5 features\\\\n representation through continuous learning , flexible\\\\n capabilities , and robust bilingual proficiency in English\\\\n, positioning it as a competitive MLLM .\\\\n30 % 及 以下\\\\n50 % -70 % ( 70 % )\\\\n26.43 %\\\\n22.91 %\\\\n30 % -50 % ( 50 % )\\\\n70 % -90 % ( 90 % )\\\\n39.21 %\\\\n5.29 %\\\\nTo bridge the gap , we introduce InternVL 1.5 , integrat-\\\\n ing three major improvements to enhance its performance\\\\n and usability . ( 1 ) We implement a continuous learning ap-\\\\n proach to a large - scale VFM - Intern ViT - 6B [ 20 ] , refining\\\\nFigure 2.\\\\n strong visual\\\\n resolution\\\\nand Chinese\\\\n第十五 届 中国 数据库 技术 大会\\\\nDATABASE TECHNOLOGY CONFERENCE CHINA 2024\\\\n行业 OCR 的 识别 度 普遍 在 70 %\\\\nDTCC\\\\n朗丽玆 西山 花园 酒店 8 月 22-24 日\\\\nDB2\\\\nMPP\\\\nIT - 168 .\\\\nU ChinaUnix\\\\nOracie\\\\nSQL\\\\nITPUB', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/1.jpg'}, 'type': 'image_url'}, {'text': 'Here is an image of a diagram or graphic. Your task is to analyze the image and provide **custom** instructions on how to convert the visual information into JSON format. **Do not paraphrase this task**. Instead, analyze the **specific relationships** within the image and create instructions based on the elements and how they are connected. Your response should be customized instructions that can be used to prompt an LLM to process the image content into a JSON format accurately and reliably.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.\\\\n\\\\n1. **List all components**: First, list all visible components in the image, such as text, numbers, arrows, lines, icons, shapes, and color coding.\\\\n  - Use any surrounding text to help clarify the purpose of each component, and explain what each component represents, with emphasis on how elements relate to each other:\\\\n  - Focus especially on **relationships** between elements, like directional arrows (e.g., flow or process sequence), placement on axes, groupings by color or proximity, and size or order comparisons. Be sure to describe each element\\'s purpose, integrating any context provided by the text.\\\\n\\\\n2. **Describe the relationship in details**: For each relationship, explain what is being conveyed and the purpose of the connection (e.g., causal flow, comparison, importance). This might include directional arrows (e.g., showing flow or sequence), visual groupings (e.g., by color or alignment), or comparative relationships (e.g., sizes, positions, or importance).\\\\n  - Avoid listing elements without context—explain each relationship in detail if it adds clarity, and refer to surrounding text if it provides insight.\\\\n  - Be specific in describing how the relationships should be represented in JSON, rather than focusing solely on individual elements.\\\\n  - For diagrams, clarify what each connection represents and the intent behind the structure.\\\\n  - For graphs, highlight patterns, trends, or notable changes (e.g., upward/downward trends, fluctuations). Summarize these trends in your instructions to be captured in JSON.\\\\n\\\\n3. **Create Summary JSON**: After identifying the components, provide instructions for creating a **summary JSON object** that captures the overall structure, meaning, and context of the image. This should include any **figure titles**, **numbers**, headers, and main topics or themes in the image. Use actual examples from the image, avoiding generic placeholders.\\\\n  - Add customized appropriate fields for the image based on your analysis. For example, for graphs, you could add a \\\\\"trends\\\\\" field. For a flow diagram, something like \\\\\"components\\\\\" attribute might make sense. **Only add these fields if they highlight key insights about the image**!\\\\n  - Use any surrounding text to help clarify the meaning, context, structure, and purpose of the image, especially for identifying the figure title and number if they are not within the image itself.\\\\n  - If a title or figure number exists in the image or surrounding text, make sure you capture this information in the summary JSON object and reflect it in the narrative.\\\\n    - Do not include the figure title and number if they cannot be found.\\\\n    - Use the nomenclature in the image. If the figure is called \\\\\"table\\\\\" call it \\\\\"table_title\\\\\" and  \\\\\"table_number\\\\\". etc...\\\\n  - Here is an example with some of the fields mentioned. Please *customize it* to the image to *capture the important information and insights* being conveyed in the image. Use real values from the image and not default values:\\\\n```\\\\n{\\\\\"figure title\\\\\":\\\\\"TITLE\\\\\",\\\\\"figure number\\\\\":1,\\\\\"description\\\\\":\\\\\"X\\\\\",\\\\\"components\\\\\":[\\\\\"Z\\\\\"],\\\\\"trends\\\\\":[\\\\\"Q\\\\\"],\\\\\"relationships\\\\\":[{\\\\\"source\\\\\":\\\\\"Process A\\\\\",\\\\\"target\\\\\":\\\\\"Process B\\\\\",\\\\\"type\\\\\":\\\\\"flow\\\\\"},{\\\\\"group\\\\\":\\\\\"blue items\\\\\",\\\\\"elements\\\\\":[\\\\\"Box 1\\\\\",\\\\\"Box 2\\\\\"]}]}\\\\n```\\\\n  - Translate all keys, values, and text into English.\\\\n\\\\n4. **Create Detailed JSON for Elements and Relationships:**: Explain how to convert each individual component into JSON that reflects its relationships with other elements, if there are relationships between elements (e.g., arrows showing direction, data points on a graph).\\\\n  - The JSON should capture connections, groupings, directionality, trends or changes observed, and other relationships between the elements, not just the elements themselves.\\\\n  - If there are **check marks**, **tick marks**, **filled boxes**, or other indicators that a value is selected:\\\\n    - **Original Text**: Create instructions to capture the question or field label as it appears, along with any numbering or lettering.\\\\n    - **Numbering or lettering**: Create instructions for capturing any numbering and lettering, if it exists, for these fields.\\\\n    - **Identify the Exact Options Available**: List each available option precisely as labeled in the table (e.g., \\\\\"Yes/No\\\\\", \\\\\"Male/Female\\\\\", \\\\\"Option A/Option B/Option C\\\\\") in your instructions.\\\\n    - Describe how to handle selection boxes:\\\\n      - For Yes/No or labeled choices, record the exact selected label (e.g., \\\\\"selected\\\\\": \\\\\"No\\\\\").\\\\n      - For single checkboxes without labels, use \\\\\"true\\\\\" or \\\\\"false\\\\\" based on whether the box is marked.\\\\n      - For multi-selections, list all selected values in an array.\\\\n    - **Precision**: Use examples matching the table\\'s visible content, avoiding assumptions.\\\\n  - For charts or data visualizations, capture every individual data point, including relative changes, and summarize the overall trend in the summary JSON object, using additional text to help explain overall patterns if relevant.\\\\n  - Translate all keys, values, and text into English.\\\\n\\\\n5. **Narrate the JSON**: Provide instructions on how to convert the JSON into full sentences. The narrative should describe each JSON object in English, detailing the relationships and meaning of each part of the image. Avoid using placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"—base the narrative on the actual content of the image.\\\\n\\\\n6. **Final JSONL and Narrative Instructions**: Instruct that the JSON objects should be grouped at the top in a JSONL format (without indentation or extra formatting). Below that, provide the narrative sentences that describe the JSON content fully.\\\\n\\\\n**Important Notes**:\\\\n- It is critical that your response is customized to the **relationships** and **insights** conveyed in the image, and not a paraphrase of these instructions.\\\\n- Use the surrounding text to capture additional context, high-level insights, or to capture the figure title and number if they are not visible within the image.\\\\n- If a title or figure number exists, make sure you capture this information in the summary JSON object and reflect it in the narrative. The figure number and title may not be in the image but may be found in the surrounding text.\\\\n- Only include fields like \\\\\"components\\\\\",\\\\\"trends\\\\\", and \\\\\"relationships\\\\\" in the summary JSON if they convey **key insights**.\\\\n- Make sure all relationships are captured, whether through arrows, lines, proximity, color coding, or other visual cues.\\\\n- Avoid placeholders like \\\\\"X\\\\\" or \\\\\"Y\\\\\"; use actual elements from the image and describe their relationships in detail.\\\\n- Translate all keys, values, and text into English.\\\\n- Ensure that the instructions are fully customized based on the content of the image. Do not paraphrase or repeat the instructions from this task request—create a custom response specific to the image provided.\\\\n\\\\n**Language Consistency**: All instructions, JSON keys, values, and the narrative description must be in **English**. Translate everything into English.', 'type': 'text'}, {'image_url': {'url': 'https://upload.eyelevel.ai/layout/raw/prod/8d520d6b-e18b-4671-80d3-0553acd3b181/a470af5f-ea5f-4790-8356-0ff566a80a69/figure-1-0.jpg'}, 'type': 'image_url'}], 'role': 'user'}], 'response_format': {'type': 'text'}, 'stop': ['==='], 'temperature': 0.3, 'top_p': 0.7}\n",
      "----\n",
      "Finished 2.json -> 200 (29.329s)\n",
      "\n",
      "=== Cost / Token Usage Data ===\n",
      "                  file  status  prompt_tokens  completion_tokens  \\\n",
      "0        api-req3.json     200           4796                681   \n",
      "1        api-req2.json     200           4796                764   \n",
      "2               5.json     200           3155               1040   \n",
      "3        api-req1.json     200           5594               1273   \n",
      "4  simple_request.json     200           3208               2192   \n",
      "5               2.json     200           5183               2282   \n",
      "\n",
      "   total_tokens estimated_cost  latency_sec  \\\n",
      "0          5477           None       12.897   \n",
      "1          5560           None       13.864   \n",
      "2          4195           None       16.556   \n",
      "3          6867           None       19.398   \n",
      "4          5400           None       28.103   \n",
      "5          7465           None       29.329   \n",
      "\n",
      "                                    response_preview  \n",
      "0  **표 분석 지침**\\n\\n1. **표 구조 분석:**\\n   - 표 제목: \"표 ...  \n",
      "1  1. **테이블 구조 분석**: 테이블의 모든 보이는 구성 요소를 식별하고 나열합니...  \n",
      "2  {\"figure_title\":\"Characteristics of InternVL 1...  \n",
      "3  Okay, here are custom instructions for convert...  \n",
      "4  1. **테이블 구조 분석:**\\n   - 테이블 제목은 \"국표 CPI 지표 급등율...  \n",
      "5  Here's a breakdown of the image analysis and c...  \n"
     ]
    }
   ],
   "source": [
    "import os, json, requests, time\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"KVANT_API_KEY\")\n",
    "\n",
    "REQUESTS_DIR = \"sample_requests\"\n",
    "FORCED_MODEL = \"inference-gemma-12b-it\"\n",
    "MAX_WORKERS = 8  # number of threads\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "def send_request(fname: str):\n",
    "    \"\"\"Send a single request and return usage/cost info.\"\"\"\n",
    "    path = os.path.join(REQUESTS_DIR, fname)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        payload = json.load(f)\n",
    "\n",
    "    # restructuring requests (must conform to user/assistant alternation)\n",
    "    replacement_messages = []\n",
    "    for message in payload['messages']:\n",
    "        if len(replacement_messages) == 0 or message['role'] != replacement_messages[-1]['role']:\n",
    "            replacement_messages.append(message)\n",
    "        else:\n",
    "            replacement_messages[-1]['content'].extend(message['content'])\n",
    "    payload['messages'] = replacement_messages\n",
    "\n",
    "    #hard coding model\n",
    "    payload[\"model\"] = FORCED_MODEL  # override model\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            \"https://maas.ai-2.kvant.cloud/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=120,\n",
    "        )\n",
    "        print('----')\n",
    "        print(payload)\n",
    "        print('----')\n",
    "        latency = time.perf_counter() - start\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "\n",
    "        usage = data.get(\"usage\", {})\n",
    "        content = \"\"\n",
    "        if \"choices\" in data and data[\"choices\"]:\n",
    "            content = data[\"choices\"][0][\"message\"].get(\"content\", \"\")[:200]\n",
    "\n",
    "        return {\n",
    "            \"file\": fname,\n",
    "            \"status\": resp.status_code,\n",
    "            \"prompt_tokens\": usage.get(\"prompt_tokens\"),\n",
    "            \"completion_tokens\": usage.get(\"completion_tokens\"),\n",
    "            \"total_tokens\": usage.get(\"total_tokens\"),\n",
    "            \"estimated_cost\": usage.get(\"estimated_cost\"),\n",
    "            \"latency_sec\": round(latency, 3),\n",
    "            \"response_preview\": content,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "        return {\n",
    "            \"file\": fname,\n",
    "            \"status\": \"error\",\n",
    "            \"prompt_tokens\": None,\n",
    "            \"completion_tokens\": None,\n",
    "            \"total_tokens\": None,\n",
    "            \"estimated_cost\": None,\n",
    "            \"latency_sec\": None,\n",
    "            \"response_preview\": f\"❌ {e}\",\n",
    "        }\n",
    "\n",
    "# Collect all JSON files\n",
    "json_files = [f for f in os.listdir(REQUESTS_DIR) if f.endswith(\".json\")]\n",
    "\n",
    "# send_request(json_files[0])\n",
    "\n",
    "records = []\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    futures = {executor.submit(send_request, fname): fname for fname in json_files}\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        records.append(result)\n",
    "        print(f\"Finished {result['file']} -> {result['status']} ({result['latency_sec']}s)\")\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(\"\\n=== Cost / Token Usage Data ===\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d6207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinfrathroughputtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
